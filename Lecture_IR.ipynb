{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture et traitement des données issues des thermo-mosaïques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import  matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from rasterio.plot import plotting_extent\n",
    "from rasterio.plot import show\n",
    "from rasterio.plot import show_hist # Useful if you wish to plot all hist and GPS target image\n",
    "from rasterio.mask import mask\n",
    "from rasterio.enums import Resampling\n",
    "from shapely.geometry.point import Point\n",
    "import shapely\n",
    "import numpy as np\n",
    "import csv\n",
    "import fiona\n",
    "from tools_AA_IR import reading_gps_file, circle_sensor, plottingtemp_single_label_IR\n",
    "from tools_AA_IR import path_IR, get_tif,get_value_IR\n",
    "from tools_AA_IR import circle_to_shape, readingIR , IR_mask, readingIR_all,alternative_readingIR_all\n",
    "from tools_AA import readingtemp_AA, slice_raw, path_sonde, name_sonde, plottingtemp_single_label\n",
    "from tools_EL import readingtemp, plottingtemp\n",
    "from tools_AA_variograms import reading_3band, reading_cluster,get_3band\n",
    "from tools_AA_variograms import reshape_3band_to_dataframe, set_bound_to_NAN\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ouverture et recupération des positions des sondes\n",
    "filename_Sensor_txt = \"./traitement_PIREN/sondes_gps_UTM31N_phase1.txt\"\n",
    "Sensor_coord = reading_gps_file(filename_Sensor_txt)\n",
    "Sensor_coord # Contient les coord de toutes les sondes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Recupere les noms des IR dans le dossier path, \n",
    "#par defaut = './traitement_PIREN/' et permet de \n",
    "#choisir n'importe quelle ortho avec son nom \n",
    "\n",
    "filetif = ['6H55','7H29','8H22','9H28','10H22','11H27','12H31','13H26','15H59','17H27']\n",
    "\n",
    "#filetif = ['6H55']\n",
    "\n",
    "\n",
    "ls_path_tif,filetif = get_tif(filetif)\n",
    "dict_IR= alternative_readingIR_all(ls_path_tif[::2],filetif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot de toutes les sondes/IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fenêtrage des sondes, création de Dict_IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.windows import Window\n",
    "def reading_1band(LONGUEUR,filetif,ls_path_tif,LABEL = \"band 1\") :\n",
    "    \"\"\" Lit un fichier .tif à 1 band et retourne un patch carré de coté LONGUEUR au format DataFrame [x,y,band 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    #filename = './traitement_PIREN/vis_piren_phase_HSV.tif'\n",
    "    #LONGUEUR = 10\n",
    "    filename_Sensor_txt = \"./traitement_PIREN/sondes_gps_UTM31N_phase1.txt\"\n",
    "    sensor_coord = reading_gps_file(filename_Sensor_txt)\n",
    "    dict_IR = {} # va contenir les noms IR + tous les dicts associés à chaque sonde\n",
    "    \n",
    "    for m,tif in enumerate(ls_path_tif) : \n",
    "        with rio.open(tif) as dataset :\n",
    "            #Value par défaut\n",
    "            #win_height = 6303\n",
    "            #win_width = 3421\n",
    "            \n",
    "\n",
    "            ls_index_target = [] # liste des valeurs indexées dans l'image\n",
    "            win_height = round(LONGUEUR / dataset.res[0])\n",
    "            win_width  = round(LONGUEUR / dataset.res[1])\n",
    "            print(\"Taille de la fenetre :\",win_height,\"x\",win_width)\n",
    "            print(\"Résolution \",\"x:\",dataset.res[0],\"y:\",dataset.res[1])\n",
    "\n",
    "            # Loop pour recuperer les coordonnées UTM et convertir en indice \n",
    "            for k in range(len(sensor_coord[\"SensorName\"])) :\n",
    "                x = sensor_coord[\"x\"][k] \n",
    "                y = sensor_coord[\"y\"][k]\n",
    "                target = dataset.index(float(x),float(y))\n",
    "                ls_index_target.append(target)\n",
    "\n",
    "            dict_windows = {} # liste des paramètres dans la création d'une window\n",
    "            dict_windows_param = {} # dict des targets : améliore la lisibilité\n",
    "\n",
    "            for i,index_target in enumerate(ls_index_target) :\n",
    "                win = Window.from_slices((index_target[0]-(win_height//2),(index_target[0]+(win_height//2))),\n",
    "                                         (index_target[1]-(win_width//2),(index_target[1]+(win_width//2)))\n",
    "                                         )\n",
    "                win_transform = dataset.window_transform(win)\n",
    "                all_band = dataset.read(1,window = win) # en cas de visualisation\n",
    "\n",
    "                dict_param = {\"win\" : win,\n",
    "                                \"win_transform\" : win_transform,\n",
    "                               \"all_band\" : all_band,\n",
    "                               \"SensorName\" : sensor_coord[\"SensorName\"][i],\n",
    "                             \"LONGUEUR\" : LONGUEUR,\n",
    "                             \"resolution\" : dataset.res}\n",
    "\n",
    "                dict_windows_param[sensor_coord[\"SensorName\"][i]] = dict_param\n",
    "\n",
    "                # Vecteurs linéaires avec valeurs uniforméments crées\n",
    "                x_start = win_transform[2]\n",
    "                x_res   = win_transform[0]\n",
    "                x_end   = x_start+(float(x_res)*win.width)\n",
    "\n",
    "                y_end   = win_transform[5]\n",
    "                y_res   = win_transform[4]\n",
    "                y_start = y_end + (float(y_res)*win.height)\n",
    "\n",
    "                #print(\"x_end =\",x_end)\n",
    "                #print(\"y_start =\",y_start)\n",
    "\n",
    "                x = np.linspace(x_start,x_end,num = win.width+1)\n",
    "                y = np.linspace(y_start,y_end,num = win.height+1)\n",
    "\n",
    "                band_1 = []\n",
    "                x_matrix = []\n",
    "                y_matrix = []\n",
    "                # Loop pour obtenir la valeur de chaque pt pour chaque band\n",
    "                \n",
    "                for j in range(len(x)) :\n",
    "                    for l in range(len(y)) :\n",
    "                        for val in dataset.sample([(x[j],y[l])]): \n",
    "                            band_1.append(val[0])\n",
    "                            x_matrix.append(x[j]) # permet de répeter le terme \n",
    "                            y_matrix.append(y[l])\n",
    "                mapping = ['x','y',LABEL]\n",
    "                DATA_WINDOW = pd.DataFrame(np.array([x_matrix,\n",
    "                                                     y_matrix,\n",
    "                                                     band_1],dtype = object).T,\n",
    "                                           columns=mapping)\n",
    "\n",
    "                DATA_WINDOW['SensorName'] = sensor_coord[\"SensorName\"][i]\n",
    "\n",
    "                dict_windows[sensor_coord[\"SensorName\"][i]] = DATA_WINDOW\n",
    "        dict_IR[\"IR_\"+filetif[m]] = {\"dict_windows\" : dict_windows,\n",
    "                                     \"dict_windows_param\" : dict_windows_param}\n",
    "        print(\"complited : \",\"IR_\"+filetif[m])\n",
    "         \n",
    "    return dict_IR  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de Dict_sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des données par ajout de bande à un DataFrame par Sonde/IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_to_DataFrame(dict_IR):\n",
    "    \"\"\"\n",
    "    Création d'un DataFrame par sonde contenant les positions et les des bandes normalisées, réunit sous \n",
    "    un dictionnaire\n",
    "    \"\"\"\n",
    "    S1 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"], dtype = float)\n",
    "    S2 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"], dtype = float)\n",
    "    S3_AIR = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"], dtype = float)\n",
    "    S4 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"], dtype = float)\n",
    "    S5 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"], dtype = float)\n",
    "    S6 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"], dtype = float)\n",
    "    S7 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"], dtype = float)\n",
    "    S8 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"], dtype = float)\n",
    "    S9 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"], dtype = float)\n",
    "    S10 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"], dtype = float)\n",
    "    dict_sensor = {\"S1\" : S1,\"S2\" : S2,\"S3-AIR\" : S3_AIR,\"S4\" : S4,\"S5\" : S5,\n",
    "                \"S6\" : S6,\"S7\" : S7,\"S8\" : S8,\"S9\" : S9,\"S10\" : S10}\n",
    "\n",
    "\n",
    "\n",
    "    for sensor in dict_sensor :\n",
    "        k = 0\n",
    "        BAND_MIN_N = 0\n",
    "        BAND_MAX_N = 0\n",
    "        for target in dict_IR :\n",
    "            min_= dict_IR[target][\"dict_windows\"][sensor][\"band 1\"].min()\n",
    "            max_= dict_IR[target][\"dict_windows\"][sensor][\"band 1\"].max()\n",
    "            if min_ < BAND_MIN_N :\n",
    "                BAND_MIN_N = min_\n",
    "\n",
    "\n",
    "            if max_ > BAND_MAX_N :\n",
    "                BAND_MAX_N = max_\n",
    "\n",
    "\n",
    "        print(\"BAND_MIN_N\",BAND_MIN_N) # valeur minimale retenue pour la normalisation\n",
    "        print(\"BAND_MAX_N\",BAND_MAX_N) # valeur maximale retenue pour la normalisation\n",
    "\n",
    "        for target in dict_IR :\n",
    "\n",
    "            band_shape = dict_IR[target][\"dict_windows\"][sensor][[\"band 1\"]].shape[0]\n",
    "\n",
    "            band_min = dict_IR[target][\"dict_windows\"][sensor][\"band 1\"].min()\n",
    "            band_max = dict_IR[target][\"dict_windows\"][sensor][\"band 1\"].max()\n",
    "\n",
    "            x = pd.DataFrame(dict_IR[target][\"dict_windows\"][sensor][\"x\"], dtype = float)\n",
    "            y = pd.DataFrame(dict_IR[target][\"dict_windows\"][sensor][\"y\"], dtype = float)\n",
    "            # band originale, sans normalisation\n",
    "            origin_band = pd.DataFrame(dict_IR[target][\"dict_windows\"][sensor][\"band 1\"], dtype = float)\n",
    "            origin_band.columns = [\"origin band\"]\n",
    "\n",
    "            # band avec normalisation différente pour chaque IR\n",
    "            band     = pd.DataFrame((dict_IR[target][\"dict_windows\"][sensor][[\"band 1\"]]-band_min)/(band_max-band_min), dtype = float)\n",
    "\n",
    "            # band avec normalisation commune pour chaque IR\n",
    "            band_N   = pd.DataFrame((dict_IR[target][\"dict_windows\"][sensor][[\"band 1\"]]-BAND_MIN_N)/(BAND_MAX_N-BAND_MIN_N), dtype = float) \n",
    "            band_N.columns = ['band N']\n",
    "\n",
    "            # Concaténation de plusieurs bandes\n",
    "            cnte = pd.concat([x,y,origin_band,band,band_N],axis=1)\n",
    "            dict_sensor[sensor]=dict_sensor[sensor].append(cnte,ignore_index=True)\n",
    "\n",
    "            # Repetition du nom de IR pour chaque valeurs -> boxplot\n",
    "            dict_sensor[sensor][\"IR\"][k:(k+band_shape)]  = target\n",
    "\n",
    "            k+=band_shape\n",
    "        print(\"completed :\",sensor)\n",
    "    return dict_sensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filetif = ['6H55','7H29','8H22','9H28','10H22','11H27','12H31','13H26',\n",
    "                               '15H59','17H27']\n",
    "\n",
    "#filetif = ['6H55']\n",
    "ls_path_tif,filetif = get_tif(filetif)\n",
    "Dimension = 4 # en m\n",
    "dict_IR = reading_1band(Dimension,filetif,ls_path_tif)\n",
    "dict_sensor = sensor_to_DataFrame(dict_IR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moyenne entre deux rayon de cercle r1 et r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_pseudo_temp(ls_path_tif,dict_IR,r1 = 0.7 , r2 = 1.5) :\n",
    "    \"\"\"\n",
    "    Création d'un dictionnaire classé par IR contenant toutes les données comprise entre un rayon r1 et r2, \n",
    "    \"\"\"\n",
    "    \n",
    "    dict_value_IR = {}\n",
    "\n",
    "    for i,IR in enumerate(dict_IR) :\n",
    "        dict_value_sensor = {}\n",
    "        with rio.open(ls_path_tif[i]) as dataset : # ouverture du fichier obligatoire pour recup la valeur\n",
    "            for sensor in dict_IR[IR][\"dict_windows\"] :\n",
    "\n",
    "                res = dict_IR[IR][\"dict_windows_param\"][sensor][\"resolution\"] # resolution [x,y]\n",
    "                sensor_dataframe = dict_IR[IR][\"dict_windows\"][sensor]\n",
    "                mid_indice = (dict_IR[IR][\"dict_windows_param\"][sensor]['win'].width) # les indices commencent à 0 !\n",
    "\n",
    "                mid_x = sensor_dataframe.iloc[len(sensor_dataframe)//2][\"x\"] \n",
    "                mid_y = sensor_dataframe.iloc[(mid_indice//2)-1][\"y\"]# la valeur du milieu est //2 \n",
    "\n",
    "                #list des valeurs autour de [0, 2pi] , mouvement anti-horaire\n",
    "                theta = np.linspace(0,np.pi*2,round(np.pi*2/res[0]))\n",
    "                ls_x = np.empty([1]) ; ls_y = np.empty([1])\n",
    "\n",
    "                #recherche de points entre deux rayon r1 et r2\n",
    "                \n",
    "                for THETA in theta :\n",
    "                    #\n",
    "                    x1 = mid_x + r1*np.cos(THETA)\n",
    "                    y1 = mid_y + r1*np.sin(THETA)\n",
    "\n",
    "                    x2 = mid_x + r2*np.cos(THETA)\n",
    "                    y2 = mid_y + r2*np.sin(THETA)\n",
    "\n",
    "                    ls_x = np.append(ls_x,np.linspace(x1,x2,round((r2-r1)/res[0]))) \n",
    "                    ls_y = np.append(ls_y,np.linspace(y1,y2,round((r2-r1)/res[1])))\n",
    "\n",
    "                ls_x = np.delete(ls_x,0) ; ls_y = np.delete(ls_y,0)\n",
    "\n",
    "\n",
    "                with rio.open(ls_path_tif[i]) as dataset : # ouverture du fichier obligatoire pour recup la valeur\n",
    "\n",
    "                    dict_IR[IR][\"dict_windows_param\"][sensor]['win'].width # résolution -> nb de pixel == nb d'indice \n",
    "\n",
    "                    ls_value = []\n",
    "                    for k in range(len(ls_x)) :\n",
    "\n",
    "                        for value in dataset.sample([(float(ls_x[k]),float(ls_y[k]))]) : \n",
    "                            ls_value.append(float(value))\n",
    "\n",
    "                    dict_value_sensor[sensor] = pd.DataFrame(np.array([ls_x,ls_y,ls_value],dtype = float).T,columns = \n",
    "                                                             [\"x\",\"y\",\"value\"])\n",
    "        print(IR)\n",
    "        dict_value_IR[IR] = dict_value_sensor\n",
    "        print(\"nombre de coordonnées utilisée pour la moyenne :\",dict_value_IR[IR][sensor].shape[0])\n",
    "        \n",
    "    return dict_value_IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation des chemins d'accès aux IRs\n",
    "filetif = ['6H55','7H29','8H22','9H28','10H22','11H27','12H31','13H26',\n",
    "                               '15H59','17H27']\n",
    "\n",
    "#filetif = [\"6H55\"]\n",
    "ls_path_tif,filetif = get_tif(filetif)\n",
    "\n",
    "# dictionnaire contenant les valeurs comprise entre les deux rayons de recherche\n",
    "dict_value_IR = get_value_pseudo_temp(ls_path_tif,dict_IR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout des fenêtres de clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_cluster_modified(LONGUEUR,filename='./traitement_PIREN/vis_piren_phase_HSV.tif', x = None,y = None) :\n",
    "    \"\"\" Lit un fichier .tif à 3 bands et retourne un patch carré de coté LONGUEUR au format csv pour une certaine coordonnée\n",
    "    x,y\n",
    "    \"\"\"\n",
    "    #filename = './traitement_PIREN/vis_piren_phase_HSV.tif'\n",
    "    #LONGUEUR = 10\n",
    "    filename_Sensor_txt = \"./traitement_PIREN/sondes_gps_UTM31N_phase1.txt\"\n",
    "    sensor_coord = reading_gps_file(filename_Sensor_txt)\n",
    "    with rio.open(filename) as dataset :\n",
    "        #Value par défaut\n",
    "        #win_height = 6303\n",
    "        #win_width = 3421\n",
    "\n",
    "        ls_index_target = [] # liste des valeurs indexées dans l'image\n",
    "        win_height = round(LONGUEUR / dataset.res[0])\n",
    "        win_width  = round(LONGUEUR / dataset.res[1])\n",
    "        print(\"Taille de la fenetre :\",win_height,\"x\",win_width)\n",
    "\n",
    "        # Loop pour recuperer les coordonnées UTM et convertir en indice \n",
    "        if x != None or y != None :\n",
    "            ls_index_target.append(dataset.index(float(x),float(y)))\n",
    "        else :\n",
    "            \n",
    "            for k in range(len(sensor_coord[\"SensorName\"])) :\n",
    "                x = sensor_coord[\"x\"][k] \n",
    "                y = sensor_coord[\"y\"][k]\n",
    "                target = dataset.index(float(x),float(y))\n",
    "                ls_index_target.append(target)\n",
    "\n",
    "        dict_windows = {} # liste des paramètres dans la création d'une window\n",
    "        dict_windows_param = {} # dict des targets : améliore la lisibilité\n",
    "\n",
    "        for i,index_target in enumerate(ls_index_target) :\n",
    "            win = Window.from_slices((index_target[0]-(win_height//2),(index_target[0]+(win_height//2))),\n",
    "                                     (index_target[1]-(win_width//2),(index_target[1]+(win_width//2)))\n",
    "                                     )\n",
    "            \n",
    "            win_transform = dataset.window_transform(win)\n",
    "            all_band = dataset.read(1,window = win) # en cas de visualisation\n",
    "\n",
    "            dict_param = {\"win\" : win,\n",
    "                            \"win_transform\" : win_transform,\n",
    "                           \"all_band\" : all_band,\n",
    "                           \"SensorName\" : sensor_coord[\"SensorName\"][i]}\n",
    "\n",
    "            dict_windows_param = dict_param\n",
    "\n",
    "            # Vecteurs linéaires avec valeurs uniforméments crées\n",
    "            x_start = win_transform[2]\n",
    "            x_res   = win_transform[0]\n",
    "            x_end   = x_start+(float(x_res)*win.width)\n",
    "\n",
    "            y_end   = win_transform[5]\n",
    "            y_res   = win_transform[4]\n",
    "            y_start = y_end + (float(y_res)*win.height)\n",
    "\n",
    "            #print(\"x_end =\",x_end)\n",
    "            #print(\"y_start =\",y_start)\n",
    "\n",
    "            x = np.linspace(x_start,x_end,num = win.width)\n",
    "            y = np.linspace(y_start,y_end,num = win.height)\n",
    "\n",
    "            band_1 = []\n",
    "            x_matrix = []\n",
    "            y_matrix = []\n",
    "            # Loop pour obtenir la valeur de chaque pt pour chaque band\n",
    "            for j in range(len(x)) :\n",
    "                for l in range(len(y)) :\n",
    "                    for val in dataset.sample([(x[j],y[l])]): \n",
    "                        label = val[0]\n",
    "                        band_1.append(label)\n",
    "                        x_matrix.append(x[j]) # permet de répeter le terme \n",
    "                        y_matrix.append(y[l])\n",
    "                        mapping = ['x','y','label']\n",
    "            DATA_WINDOW = pd.DataFrame(np.array([x_matrix,\n",
    "                                                 y_matrix,\n",
    "                                                 band_1],dtype = object).T,\n",
    "                                       columns=mapping)\n",
    "            \n",
    "         \n",
    "            \n",
    "    return DATA_WINDOW, dict_windows_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_3band_modified(LONGUEUR,filename='./traitement_PIREN/vis_piren_phase_HSV.tif',normalization = True, x = None,y = None) :\n",
    "    \"\"\" Lit un fichier .tif à 3 bands et retourne un patch carré de coté LONGUEUR au format csv pour l'execution d'un variogram\n",
    "    \"\"\"\n",
    "    #filename = './traitement_PIREN/vis_piren_phase_HSV.tif'\n",
    "    #LONGUEUR = 10\n",
    "    filename_Sensor_txt = \"./traitement_PIREN/sondes_gps_UTM31N_phase1.txt\"\n",
    "    sensor_coord = reading_gps_file(filename_Sensor_txt)\n",
    "    with rio.open(filename) as dataset :\n",
    "        #Value par défaut\n",
    "        #win_height = 6303\n",
    "        #win_width = 3421\n",
    "\n",
    "        ls_index_target = [] # liste des valeurs indexées dans l'image\n",
    "        win_height = round(LONGUEUR / dataset.res[0])\n",
    "        win_width  = round(LONGUEUR / dataset.res[1])\n",
    "        print(\"Taille de la fenetre :\",win_height,\"x\",win_width)\n",
    "\n",
    "        # Loop pour recuperer les coordonnées UTM et convertir en indice \n",
    "        if x != None or y != None :\n",
    "            \n",
    "            ls_index_target.append(dataset.index(float(x),float(y)))\n",
    "            \n",
    "        else :\n",
    "            \n",
    "            for k in range(len(sensor_coord[\"SensorName\"])) :\n",
    "                x = sensor_coord[\"x\"][k] \n",
    "                y = sensor_coord[\"y\"][k]\n",
    "                target = dataset.index(float(x),float(y))\n",
    "                ls_index_target.append(target)\n",
    "\n",
    "        dict_windows = {} # liste des paramètres dans la création d'une window\n",
    "        dict_windows_param = {} # dict des targets : améliore la lisibilité\n",
    "\n",
    "        for i,index_target in enumerate(ls_index_target) :\n",
    "            win = Window.from_slices((index_target[0]-(win_height//2),(index_target[0]+(win_height//2))),\n",
    "                                     (index_target[1]-(win_width//2),(index_target[1]+(win_width//2)))\n",
    "                                     )\n",
    "            win_transform = dataset.window_transform(win)\n",
    "            all_band = dataset.read([1,2,3],window = win) # en cas de visualisation\n",
    "\n",
    "            dict_param = {\"win\" : win,\n",
    "                            \"win_transform\" : win_transform,\n",
    "                           \"all_band\" : all_band,\n",
    "                           \"SensorName\" : sensor_coord[\"SensorName\"][i]}\n",
    "\n",
    "            dict_windows_param[sensor_coord[\"SensorName\"][i]] = dict_param\n",
    "\n",
    "            # Vecteurs linéaires avec valeurs uniforméments crées\n",
    "            x_start = win_transform[2]\n",
    "            x_res   = win_transform[0]\n",
    "            x_end   = x_start+(float(x_res)*win.width)\n",
    "\n",
    "            y_end   = win_transform[5]\n",
    "            y_res   = win_transform[4]\n",
    "            y_start = y_end + (float(y_res)*win.height)\n",
    "\n",
    "            #print(\"x_end =\",x_end)\n",
    "            #print(\"y_start =\",y_start)\n",
    "\n",
    "            x = np.linspace(x_start,x_end,num = win.width)\n",
    "            y = np.linspace(y_start,y_end,num = win.height)\n",
    "\n",
    "            band_1 = []\n",
    "            band_2 = []\n",
    "            band_3 = []\n",
    "            band_RGB = []\n",
    "            band_greeness =[]\n",
    "            x_matrix = []\n",
    "            y_matrix = []\n",
    "            # Loop pour obtenir la valeur de chaque pt pour chaque band\n",
    "            if normalization == False :\n",
    "                for j in range(len(x)) :\n",
    "                    for l in range(len(y)) :\n",
    "                        for val in dataset.sample([(x[j],y[l])]): \n",
    "                            R = val[0]\n",
    "                            G = val[1]\n",
    "                            B = val[2]\n",
    "                            band_1.append(R)\n",
    "                            band_2.append(G)\n",
    "                            band_3.append(B)\n",
    "                            x_matrix.append(x[j]) # permet de répeter le terme \n",
    "                            y_matrix.append(y[l])\n",
    "                            mapping = ['x','y','band 1','band 2','band 3']\n",
    "                DATA_WINDOW = pd.DataFrame(np.array([x_matrix,\n",
    "                                                     y_matrix,\n",
    "                                                     band_1,\n",
    "                                                     band_2,\n",
    "                                                     band_3],dtype = object).T,\n",
    "                                           columns=mapping)\n",
    "                        \n",
    "            else :\n",
    "                for j in range(len(x)) :\n",
    "                    for l in range(len(y)) :\n",
    "                        for val in dataset.sample([(x[j],y[l])]): \n",
    "                            R = val[0]\n",
    "                            G = val[1]\n",
    "                            B = val[2]\n",
    "                            band_1.append(R)\n",
    "                            band_2.append(G)\n",
    "                            band_3.append(B)\n",
    "                            RGB = np.sqrt(R**2 + G**2 + B**2)\n",
    "                            Greeness = G/(R+G+B)\n",
    "                            band_RGB.append(RGB)\n",
    "                            band_greeness.append(Greeness)\n",
    "                            x_matrix.append(x[j]) # permet de répeter le terme \n",
    "                            y_matrix.append(y[l])\n",
    "                            \n",
    "                mapping = ['x','y','band 1',\n",
    "                           'band 2','band 3',\n",
    "                           'band RGB','band Greensess']\n",
    "                print(len(band_greeness))\n",
    "                DATA_WINDOW = pd.DataFrame(np.array([x_matrix,\n",
    "                                                     y_matrix,\n",
    "                                                     band_1,\n",
    "                                                     band_2,\n",
    "                                                     band_3,\n",
    "                                                    band_RGB,\n",
    "                                                     band_greeness],\n",
    "                                                    dtype = object).T,\n",
    "                                           columns=mapping)\n",
    "   \n",
    "            DATA_WINDOW['SensorName'] = sensor_coord[\"SensorName\"][i]\n",
    "            \n",
    "         \n",
    "            \n",
    "    return dict_param, DATA_WINDOW  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichier .tif contenant les clusters \n",
    "fileout_cluster_vis = \"./traitement_PIREN/vis_piren_phase_1_cropped_clustered_7k.tif\"\n",
    "print(\"file cluster :\",fileout_cluster_vis)\n",
    "\n",
    "dict_windows_cluster, dict_windows_param_cluster = reading_cluster(10,fileout_cluster_vis)#,x = 523630,y = 5366180)\n",
    "\n",
    "# Fichier original \n",
    "\n",
    "filename_vis = './traitement_PIREN/vis_piren_phase1_ortho_UTM31N.tif'\n",
    "print(\"file 3band :\",filename_vis)\n",
    "dict_windows, dict_windows_param = reading_3band(10,filename_vis,False)#,x = 523630,y = 5366180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ajout des labels de clusterings pour box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in dict_windows : \n",
    "    dict_windows[sensor][\"clustering_label\"] = dict_windows_cluster[sensor][\"label\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fichier .tif contenant les clusters \n",
    "fileout_cluster_hsv = \"./traitement_PIREN/vis_piren_phase_1_cropped_HSV_clustered_7k.tif\"\n",
    "print(\"file cluster :\",fileout_cluster_hsv)\n",
    "\n",
    "dict_windows_cluster_hsv, dict_windows_param_cluster_hsv = reading_cluster(10,fileout_cluster_hsv)#,x = 523630,y = 5366180)\n",
    "\n",
    "# Fichier original \n",
    "\n",
    "filename_hsv = \"./traitement_PIREN/vis_piren_phase_1_cropped_HSV.tif\"\n",
    "print(\"file 3band :\",filename_hsv)\n",
    "dict_windows_hsv, dict_windows_param_hsv = reading_3band(10,filename_hsv,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ajout des labels de clusterings pour box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in dict_windows_hsv : \n",
    "    dict_windows_hsv[sensor][\"clustering_label\"] = dict_windows_cluster_hsv[sensor][\"label\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajout des températures pour une date donnée en DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A MODIFIER \n",
    "date_1='2019-04-14 06:00:00'\n",
    "date_2='2019-04-14 18:30:00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_temp_sensor_function(date_1,date_2) :\n",
    "    \"\"\"\n",
    "    Dictionnaire regroupant les DATAFRAMES tronquées aux dates souhaitées \n",
    "    \"\"\"\n",
    "    \n",
    "    ls_path = path_sonde()\n",
    "    dict_temp_sensor = {}\n",
    "    for i,ls_path_sonde in enumerate(ls_path):\n",
    "        name = ls_path_sonde[0][ls_path_sonde[0].find(\"S\"):(ls_path_sonde[0].find(\".csv\"))]\n",
    "        Raw = readingtemp(ls_path_sonde[0])\n",
    "        if name == \"S3AIR\" : #différence entre le nom du fichier et le reste du code.\n",
    "            name = \"S3-AIR\"\n",
    "        dict_temp_sensor[name] = slice_raw(Raw,date_1,date_2)\n",
    "        print(\"completed :\",name)\n",
    "    \n",
    "    return dict_temp_sensor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_temp_sensor = dict_temp_sensor_function(date_1,date_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout des Pseudos-Températures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pseudo_temp(dict_value_IR) :\n",
    "    \"\"\"\n",
    "    Fonction qui permet d'établir les valeurs de Pseudo-température (Signal IR aux emplacements des sondes)\n",
    "    \"\"\"\n",
    "    \n",
    "    requested_sonde = ['S1', 'S10', 'S2', 'S3-AIR', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9']\n",
    "    pseudo_temp = {}\n",
    "    for sonde in requested_sonde :\n",
    "        pseudo_temp_IR = {}\n",
    "        for IR in dict_value_IR :\n",
    "\n",
    "            var = dict_value_IR[IR][sonde][\"value\"].std()\n",
    "            mean = dict_value_IR[IR][sonde][\"value\"].mean()\n",
    "            print(sonde,IR,var,\"mean :\",mean)\n",
    "            pseudo_temp_IR[IR] = {\"values\" : mean,\n",
    "                                  \"var\" : var,\n",
    "                                  \"time\" : np.NAN }\n",
    "            print(\"var :\",pseudo_temp_IR[IR]['var'])\n",
    "            pseudo_temp_IR[IR]['time'] = pd.Timestamp(str('2019-04-14' +' '\n",
    "                                                          +IR[IR.find('_')+1:IR.find(('H'))] + ':' + \n",
    "                                                          IR[IR.find('H')+1::] )).round('30min')\n",
    "        \n",
    "        pseudo_temp[sonde] = pseudo_temp_IR\n",
    "        \n",
    "    return pseudo_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_temp = evaluate_pseudo_temp(dict_value_IR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localisation des sondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_Sensor_txt = \"./traitement_PIREN/sondes_gps_UTM31N_phase1.txt\"\n",
    "sensor_coord = reading_gps_file(filename_Sensor_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plottingtemp_single_label_IR_a(Raw,fig,ax1,label,step,random_color = np.random.randint(10)):\n",
    "    \"\"\"\n",
    "    Plot d'un seul capteur (T1,..,T4) pour toutes les sondes\n",
    "    \"\"\"\n",
    "    coloration=plt.cm.Set1(np.linspace(0,1,10))\n",
    "    \n",
    "    dict_label = {'T1' :'T1-0.50','T2' :'T2-0.35','T3' :'T3-0.20','T4' :'T4-0.05'}\n",
    "    for name in Raw[\"SensorName\"] :\n",
    "        ss = name\n",
    "        \n",
    "    label_name = ss+str(dict_label[str(label)])\n",
    "    ax1.plot(Raw['Time'], Raw[str(label)], color=coloration[random_color,:],label=label_name,linewidth = 3)\n",
    "    plt.xticks(Raw.Time[::step])\n",
    "    plt.title(ss,fontsize = 20)\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Temp [C]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en place d'une interpolation sur la PT° et la RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_rms_function(dict_sensor,dict_value_IR,dict_temp_sensor,pseudo_temp) :\n",
    "    \"\"\"\n",
    "    Création d'un dictionnaire de sonde contenant toutes les données relatives aux valeurs de RMS/RMSE des PT°,\n",
    "    contient aussi timestamps de chaque PT°\n",
    "    \"\"\"\n",
    "    dict_rms = {}\n",
    "    dict_initial_value = {}\n",
    "    for k,sensor in enumerate(dict_sensor) :\n",
    "        ls_values = [] # listes des valeurs\n",
    "        ls_time   = [] # listes des temps \n",
    "        ls_var    = [] # listes des écarts-types\n",
    "        rms       = [] # listes des RMS\n",
    "        ls_slice_value = []\n",
    "        \n",
    "        for IR in dict_value_IR :\n",
    "            ls_values.append(pseudo_temp[sensor][IR][\"values\"])\n",
    "            ls_time.append(pseudo_temp[sensor][IR][\"time\"])\n",
    "            ls_var.append(pseudo_temp[sensor][IR][\"var\"])\n",
    "            print(ls_time)\n",
    "\n",
    "        SLICE = dict_temp_sensor[sensor] # valeurs relative à la sonde de température\n",
    "\n",
    "        ## valeurs de RMS\n",
    "        for w in range(len(ls_time)) :\n",
    "            y_actual    = SLICE.loc[SLICE[\"Time\"]==ls_time[w]][\"T4\"]\n",
    "            y_predicted = ls_values[w]\n",
    "            rms.append(np.mean(y_actual-y_predicted))\n",
    "\n",
    "        # Affichage des valeurs de RMSE\n",
    "        for time in ls_time : # compare uniquement les pseudo-temp et les valeurs de sonde \n",
    "            ls_slice_value.append(float(SLICE[\"T4\"].loc[SLICE['Time'] == time]))\n",
    "        RMSE = mean_squared_error(ls_slice_value,ls_values,squared=False)\n",
    "        \n",
    "        dict_rms[sensor] = {\"RMS\" : rms ,\n",
    "                            \"Time\" : ls_time ,\n",
    "                            \"RMSE\" : RMSE, \n",
    "                            'pseudo_temp' : ls_values }\n",
    "        \n",
    "        print(\"completed :\",sensor)\n",
    "        \n",
    "    return dict_rms \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rms = dict_rms_function(dict_sensor,dict_value_IR,dict_temp_sensor,pseudo_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation sur la RMS / Création de dict_sensor_calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_RMS(dict_sensor,dict_rms):\n",
    "    \"\"\"\n",
    "    Fonction d'interpolation des valeurs de RMS défini comme la différence entre la PT° et la T° d'une sonde\n",
    "    Renvoi un dictionnaire trié par sonde comprenant une valeur toutes les 15 minutes, (pas de DataFrame)\n",
    "    \"\"\"\n",
    "    dict_sensor_calibration = {}\n",
    "    for sensor in dict_sensor :\n",
    "        \n",
    "        x = [(times.minute + times.hour * 60) for times in dict_rms[sensor][\"Time\"]] # conversion Timestamp to minutes\n",
    "        y = dict_rms[sensor][\"RMS\"]\n",
    "        start_day = dict_rms[sensor][\"Time\"][0]\n",
    "        end_day = dict_rms[sensor][\"Time\"][-1]\n",
    "        \n",
    "        f = interp1d(x,y,kind = \"cubic\")\n",
    "        xnew = [(times.minute + times.hour * 60) for times in pd.date_range(start_day,end_day,freq = \"15min\")]\n",
    "        # création d'une valeur toutes les 15 minutes\n",
    "        ynew = f(xnew)\n",
    "        dict_sensor_calibration[sensor] = {\"Interpolate_time\" : pd.date_range(start_day,end_day,freq = \"15min\"),\n",
    "                                      \"Interpolate_value\" : ynew }\n",
    "        \n",
    "        print(\"completed :\",sensor)\n",
    "    return dict_sensor_calibration\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_sensor_calibration = interpolate_RMS(dict_sensor,dict_rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajout d'une colonne label dans le DataFrame dict_sensor (dictionnaire des sondes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetif = ['6H55','7H29','8H22','9H28','10H22','11H27','12H31','13H26',\n",
    "                               '15H59','17H27']\n",
    "ls_path_tif_IR,filetif = get_tif(filetif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_sensor = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]\n",
    "cluster_tif = \"./traitement_PIREN/vis_piren_phase_1_cropped_clustered_7k.tif\"\n",
    "\n",
    "# dict_sensor : contient toutes les valeurs IR pour chaque sonde\n",
    "\n",
    "with rio.open(cluster_tif) as dataset :\n",
    "    for sensor in dict_sensor : \n",
    "        ls_test = []\n",
    "        for path in ls_path_tif_IR :\n",
    "            \n",
    "            # A modifier : on retrouve le nom de l'IR \n",
    "            IR = \"IR_\" + path[path.find('_',20)+1 : path.find('_',23) ]\n",
    "            # list des coordonnées x et y des IRs \n",
    "            x = list(dict_sensor[sensor].loc[dict_sensor[sensor][\"IR\"]== IR][\"x\"])\n",
    "            y = list(dict_sensor[sensor].loc[dict_sensor[sensor][\"IR\"]== IR][\"y\"])\n",
    "\n",
    "            for k in range(len(x)) :\n",
    "\n",
    "                for value in dataset.sample([(float(x[k]),float(y[k]))]) : \n",
    "\n",
    "                    ls_test.append(int(value))\n",
    "        print(sensor)\n",
    "        dict_sensor[sensor][\"clustering_label_vis\"] = np.array(ls_test,dtype = float)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "requested_sensor = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]\n",
    "cluster_tif = \"./traitement_PIREN/vis_piren_phase_1_cropped_HSV_clustered_7k.tif\"\n",
    "\n",
    "# dict_sensor : contient toutes les valeurs IR pour chaque sonde\n",
    "\n",
    "with rio.open(cluster_tif) as dataset :\n",
    "    for sensor in dict_sensor : \n",
    "        ls_test = []\n",
    "        for path in ls_path_tif_IR :\n",
    "            \n",
    "            # A modifier : on retrouve le nom de l'IR \n",
    "            IR = \"IR_\" + path[path.find('_',20)+1 : path.find('_',23) ]\n",
    "            # list des coordonnées x et y des IRs \n",
    "            x = list(dict_sensor[sensor].loc[dict_sensor[sensor][\"IR\"]== IR][\"x\"])\n",
    "            y = list(dict_sensor[sensor].loc[dict_sensor[sensor][\"IR\"]== IR][\"y\"])\n",
    "\n",
    "            for k in range(len(x)) :\n",
    "\n",
    "                for value in dataset.sample([(float(x[k]),float(y[k]))]) : \n",
    "\n",
    "                    ls_test.append(int(value))\n",
    "        print(sensor)\n",
    "        dict_sensor[sensor][\"clustering_label_hsv\"] = np.array(ls_test,dtype = float)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tif = \"./traitement_PIREN/vis_piren_phase_1_cropped_HSV_clustered_7k.tif\"\n",
    "with rio.open(cluster_tif) as dataset :\n",
    "    print(dataset.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphique : Pseudo-Temps vs Temp pour toutes les profondeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Représenter le niveau de linéarité entre les pseudos-temépératures (moyenne du signal IR autour d'une sonde) et les températures des sondes à toutes profondeurs.\n",
    "<ul>\n",
    "<li> un graphique / heure</li>\n",
    "<li> une couleur par profondeur</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_temp_sensor[sensor] ##Contient les données brutes de température pr chaque capteur \n",
    "pseudo_temp[sensor][IR]['values'] ## Contient les valeurs de pseudo-température par sensor/ par IR\n",
    "pseudo_temp[sensor][IR]['time'] ## Contient l'heure au format Timestamp d'une IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_PT_all_temp = {}\n",
    "for IR in dict_IR :\n",
    "    T1 = []\n",
    "    T2 = []\n",
    "    T3 = []\n",
    "    T4 = []\n",
    "    Sensor_list = {}\n",
    "    IR_temp_value = []\n",
    "    for sensor in dict_temp_sensor :\n",
    "        if sensor != 'S3-AIR' :\n",
    "            IR_time = pseudo_temp[sensor][IR]['time'] # Heure de vol\n",
    "            IR_temp_value.append(pseudo_temp[sensor][IR]['values']) # liste des pseudo-températures\n",
    "            Sensor_list.update({sensor : pseudo_temp[sensor][IR]['values']})\n",
    "            \n",
    "            # Liste des température , T1 : 0.5 / T2 : 0.35 / T3 : 0.20 / T4 : 0.05\n",
    "            T1.append(dict_temp_sensor[sensor].loc[dict_temp_sensor[sensor][\"Time\"] == IR_time][\"T1\"].to_list()[0])\n",
    "            T2.append(dict_temp_sensor[sensor].loc[dict_temp_sensor[sensor][\"Time\"] == IR_time][\"T2\"].to_list()[0])\n",
    "            T3.append(dict_temp_sensor[sensor].loc[dict_temp_sensor[sensor][\"Time\"] == IR_time][\"T3\"].to_list()[0])\n",
    "            T4.append(dict_temp_sensor[sensor].loc[dict_temp_sensor[sensor][\"Time\"] == IR_time][\"T4\"].to_list()[0])\n",
    "    \n",
    "    \n",
    "    dict_PT_all_temp[IR] = {\"T1\" : T1,\n",
    "                            \"T2\" : T2,\n",
    "                            \"T3\" : T3,\n",
    "                            \"T4\" : T4,\n",
    "                            \"IR_time\" : IR_time,\n",
    "                            \"IR_temp_value\" : IR_temp_value,\n",
    "                            \"Sensor_list\" : Sensor_list}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_PT_all_temp.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"dict_PT_all_temp_labelized_cluster.npy\",dict_PT_all_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PT vs T pour chaque thermomosaïque (Rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste popur chacun des capteurs\n",
    "Temp_T1= []\n",
    "Temp_T2= []\n",
    "Temp_T3= []\n",
    "Temp_T4= []\n",
    "Pseudo_Temperature_list = []\n",
    "for flight in dict_PT_all_temp :\n",
    "    IR = dict_PT_all_temp[flight]\n",
    "    Pseudo_Temperature = IR['IR_temp_value']\n",
    "    for ii,TEMP in enumerate([\"T1\",\"T2\",\"T3\",\"T4\"]) :\n",
    "        Temp = IR[TEMP]\n",
    "    for TEMP in [\"T1\"] :\n",
    "        Temp_T1.append(IR[TEMP])\n",
    "    for TEMP in [\"T2\"] :\n",
    "        Temp_T2.append(IR[TEMP])\n",
    "    for TEMP in [\"T3\"] :\n",
    "        Temp_T3.append(IR[TEMP])\n",
    "    for TEMP in [\"T4\"] :\n",
    "        Temp_T4.append(IR[TEMP])\n",
    "    Pseudo_Temperature_list.append(Pseudo_Temperature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Paramètres d'affichage\n",
    "requested_IR = ['IR_6H55']\n",
    "color = [\"orangered\",\"dodgerblue\",\"goldenrod\",\"seagreen\"]\n",
    "LABEL = ['T1-0.50','T2-0.35','T3-0.20','T4-0.05']\n",
    "list_markersize = [12,8,8,8]\n",
    "\n",
    "\n",
    "\n",
    "for flight in dict_PT_all_temp :\n",
    "    fig,ax = plt.subplots(1,figsize=(7,7))\n",
    "    IR = dict_PT_all_temp[flight]\n",
    "    Pseudo_Temperature = IR['IR_temp_value']\n",
    "    for ii,TEMP in enumerate([\"T1\",\"T2\",\"T3\",\"T4\"]) :\n",
    "        Temp = IR[TEMP] # list des températures par capteur\n",
    "        corr = np.corrcoef(np.array([Pseudo_Temperature]), np.array([Temp]))[0, 1] # coeff de pearson\n",
    "        \n",
    "        ax.plot(Pseudo_Temperature, Temp, color[ii],\n",
    "                marker = 'o',linestyle= 'none',markersize = list_markersize[ii],\n",
    "                label = LABEL[ii]+\", corr : \" + \"{:.2f}\".format(corr)+ \", $\\sigma^{2}$ :\" + \"{:.2f}\".format(np.asarray(Temp).var()))\n",
    "\n",
    "    ax.set_xlabel(\"Pseudo-Température\", size = 15)\n",
    "    ax.set_xlim([-3,25])\n",
    "    ax.set_ylabel(\"Température des sondes T(°C)\", size = 13)\n",
    "    ax.set_ylim([-3,25])\n",
    "    ax.set_title(flight)\n",
    "    ax.grid()\n",
    "    ax.legend(fontsize = 14 )\n",
    "\n",
    "    SAVE = True\n",
    "    if SAVE : \n",
    "        filepath = \"C:/Users/Alexandre/Desktop/Cours/Stage/Rapport/Lien PT_T/\" + str(flight)+'.png'\n",
    "        plt.savefig(filepath, bbox_inches=\"tight\")\n",
    "        filepath = \"C:/Users/Alexandre/Desktop/Cours/Stage/Modification/Lien PT_T/\" + str(flight)+'.png'\n",
    "        plt.savefig(filepath, bbox_inches=\"tight\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution des données : Chaque capteur pour une thermomosaïque donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Création d'un dictionnaire contenant les valeurs de distribution pr toutes les IRs\n",
    "requested_IR = ['IR_6H55']\n",
    "color = [\"orangered\",\"dodgerblue\",\"goldenrod\",\"seagreen\"]\n",
    "LABEL = ['T1-0.50','T2-0.35','T3-0.20','T4-0.05']\n",
    "dict_corr = {} # Contient toutes les DataFrames\n",
    "for flight in dict_PT_all_temp :\n",
    "    IR = dict_PT_all_temp[flight]\n",
    "    Pseudo_Temperature = IR['IR_temp_value']\n",
    "    dict_IR_corr = {} # contient les DataFrames par IR \n",
    "    for ii,TEMP in enumerate([\"T1\",\"T2\",\"T3\",\"T4\"]) :\n",
    "        Temp = IR[TEMP]\n",
    "        Primary = pd.DataFrame()\n",
    "        ## Calcul du normal score -> Primary/Secondary\n",
    "        Primary[\"Temp\"] = Temp\n",
    "        Primary[\"Primary\"] = (Primary[\"Temp\"] - Primary[\"Temp\"].mean())/ Primary[\"Temp\"].std()\n",
    "\n",
    "        Primary[\"pseudo_temp\"] = Pseudo_Temperature\n",
    "        Primary[\"Secondary\"] = (Primary[\"pseudo_temp\"] - Primary[\"pseudo_temp\"].mean())/ Primary[\"pseudo_temp\"].std()\n",
    "        dict_IR_corr[TEMP] = Primary\n",
    "        \n",
    "    dict_corr[flight] = dict_IR_corr\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "requested_IR = dict_corr['IR_10H22']\n",
    "requested_filename = 'IR_10H22'\n",
    "\n",
    "for TEMP in requested_IR :\n",
    "    Primary = requested_IR[TEMP]\n",
    "    # Set up the axes with gridspec\n",
    "    corr = np.corrcoef(Primary[\"Primary\"], Primary[\"Secondary\"])[0, 1]\n",
    "    vlim = (-3, 3)\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    grid = plt.GridSpec(4, 4, hspace=0.5, wspace=0.5)\n",
    "    main_ax = fig.add_subplot(grid[:-1, 1:])\n",
    "    y_hist = fig.add_subplot(grid[:-1, 0], xticklabels=[], sharey=main_ax)\n",
    "    x_hist = fig.add_subplot(grid[-1, 1:], yticklabels=[], sharex=main_ax)\n",
    "\n",
    "    # scatter points on the main axes\n",
    "    main_ax.plot(Primary[\"Primary\"], Primary[\"Secondary\"], \"ok\", markersize=3)\n",
    "    main_ax.set_xlim(vlim)\n",
    "    main_ax.set_ylim(vlim)\n",
    "    main_ax.set_title(requested_filename +' : '+ TEMP , size=15)\n",
    "    main_ax.text(-2.5, 2.2,\n",
    "        \"Corr = {0:.3f}\".format(\n",
    "            np.corrcoef(Primary[\"Primary\"], Primary[\"Secondary\"])[0, 1]\n",
    "        ),\n",
    "        size=15\n",
    "    )\n",
    "\n",
    "    # histogram on the attached axes\n",
    "    x_hist.hist(\n",
    "        Primary[\"Primary\"],\n",
    "        40,\n",
    "        histtype=\"stepfilled\",\n",
    "        label=\"Primary\",\n",
    "        orientation=\"vertical\",\n",
    "        color=\"gray\",\n",
    "        range=vlim,\n",
    "    )\n",
    "    x_hist.set_xlabel(\"Primary Histogram\", size=20)\n",
    "    x_hist.invert_yaxis()\n",
    "\n",
    "\n",
    "    y_hist.hist(\n",
    "        Primary[\"Secondary\"],\n",
    "        40,\n",
    "        histtype=\"stepfilled\",\n",
    "        orientation=\"horizontal\",\n",
    "        color=\"gray\",\n",
    "        range=vlim,\n",
    "    )\n",
    "    y_hist.set_ylabel(\"Secondary Histogram\", size=20)\n",
    "    y_hist.invert_xaxis()\n",
    "    \n",
    "    SAVE = True\n",
    "    if SAVE : \n",
    "        filepath = \"C:/Users/Alexandre/Desktop/Cours/Stage/CoCalc/DTP/linear_all_IR/distr/\" + requested_filename +'_'+TEMP+'.png'\n",
    "        plt.savefig(filepath, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PT vs T sol pour tous les vol par sonde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dict_PT_single_sensor : contient les valeurs T1->T4 pour une unique sonde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_PT_single_sensor = {}\n",
    "for IR in dict_IR :\n",
    "    T1 = {}\n",
    "    T2 = {}\n",
    "    T3 = {}\n",
    "    T4 = {}\n",
    "    Sensor_list = {}\n",
    "    IR_temp_value = []\n",
    "    for sensor in dict_temp_sensor :\n",
    "        if sensor != 'S3-AIR' :\n",
    "            IR_time = pseudo_temp[sensor][IR]['time'] # Heure de vol\n",
    "            IR_temp_value.append(pseudo_temp[sensor][IR]['values']) # liste des pseudo-températures\n",
    "            Sensor_list.update({sensor : pseudo_temp[sensor][IR]['values']})\n",
    "            \n",
    "            # Liste des température , T1 : 0.5 / T2 : 0.35 / T3 : 0.20 / T4 : 0.05\n",
    "            T1.update({sensor : dict_temp_sensor[sensor].loc[dict_temp_sensor[sensor][\"Time\"] == IR_time][\"T1\"].to_list()[0]})\n",
    "            T2.update({sensor : dict_temp_sensor[sensor].loc[dict_temp_sensor[sensor][\"Time\"] == IR_time][\"T2\"].to_list()[0]})\n",
    "            T3.update({sensor : dict_temp_sensor[sensor].loc[dict_temp_sensor[sensor][\"Time\"] == IR_time][\"T3\"].to_list()[0]})\n",
    "            T4.update({sensor : dict_temp_sensor[sensor].loc[dict_temp_sensor[sensor][\"Time\"] == IR_time][\"T4\"].to_list()[0]})\n",
    "    \n",
    "    \n",
    "    dict_PT_single_sensor[IR] = {\"T1\" : T1,\n",
    "                                 \"T2\" : T2,\n",
    "                                 \"T3\" : T3,\n",
    "                                 \"T4\" : T4,\n",
    "                                 \"IR_time\" : IR_time,\n",
    "                                 \"IR_temp_value\" : IR_temp_value,\n",
    "                                 \"Sensor_list\" : Sensor_list}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Paramètres d'affichage\n",
    "\n",
    "requested_sensor = dict_PT_single_sensor[\"IR_6H55\"][\"Sensor_list\"] # affiche toutes les sondes\n",
    "color = [\"orangered\",\"dodgerblue\",\"goldenrod\",\"seagreen\"]\n",
    "LABEL = ['T1-0.50','T2-0.35','T3-0.20','T4-0.05']\n",
    "list_markersize = [10,6,8,8]\n",
    "\n",
    "for sensor in requested_sensor :\n",
    "    fig,ax = plt.subplots(1,figsize=(7,7))\n",
    "    Pseudo_Temperature = []\n",
    "    count = 0\n",
    "    for flight in dict_PT_single_sensor :\n",
    "        IR = dict_PT_single_sensor[flight]\n",
    "        Pseudo_Temperature = IR['Sensor_list'][sensor]\n",
    "        for ii,TEMP in enumerate([\"T1\",\"T2\",\"T3\",\"T4\"]) :\n",
    "            Temp = IR[TEMP][sensor]\n",
    "            \n",
    "            if count <= 3 :\n",
    "                #corr = np.corrcoef(np.array([Pseudo_Temperature]), np.array([Temp]))[0, 1]\n",
    "                ax.plot(Pseudo_Temperature, Temp, color[ii],\n",
    "                        marker = 'o',linestyle= 'none',markersize = list_markersize[ii],\n",
    "                        label = LABEL[ii])\n",
    "            else :\n",
    "                ax.plot(Pseudo_Temperature, Temp, color[ii],\n",
    "                        marker = 'o',linestyle= 'none',markersize = list_markersize[ii])\n",
    "            \n",
    "            count +=1\n",
    "            #print(TEMP,sensor,flight,Temp,  \"|\")\n",
    "            \n",
    "    x = np.arange(-5,28)\n",
    "    y = np.arange(-5,28)\n",
    "    ax.plot(x,y,\"grey\")\n",
    "    ax.legend(loc = \"best\")\n",
    "    ax.set_xlabel(\"Pseudo-Température\", size = 15)\n",
    "    ax.set_xlim([-5,25])\n",
    "    ax.set_ylabel(\"Température des sondes T(°C)\", size = 13)\n",
    "    ax.set_ylim([-5,25])\n",
    "    ax.set_title(sensor)\n",
    "    ax.grid()\n",
    "\n",
    "    SAVE = True\n",
    "    if SAVE : \n",
    "        print(sensor)\n",
    "        filepath = \"C:/Users/Alexandre/Desktop/Cours/Stage/Modification/PT_T en fonction des sondes/\" + str(sensor)+'.png'\n",
    "        plt.savefig(filepath, bbox_inches=\"tight\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-sampling du cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fichier .tif contenant les clusters \n",
    "\n",
    "` fileout_cluster_hsv = \"./traitement_PIREN/vis_piren_phase_1_cropped_HSV_clustered_7k.tif\"\n",
    "print(\"file cluster :\",fileout_cluster_hsv)\n",
    "dict_windows_cluster_hsv, dict_windows_param_cluster_hsv = reading_cluster(4,fileout_cluster_hsv)`\n",
    "\n",
    "### Fichier original \n",
    "\n",
    "`filename_hsv = \"./traitement_PIREN/vis_piren_phase_1_cropped_HSV.tif\"\n",
    "print(\"file 3band :\",filename_hsv)\n",
    "dict_windows_hsv, dict_windows_param_hsv = reading_3band(4,filename_hsv,False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileout_cluster_hsv = \"./traitement_PIREN/vis_piren_phase_1_cropped_HSV_clustered_7k.tif\"\n",
    "print(\"file cluster :\",fileout_cluster_hsv)\n",
    "fileout_IR = \"./traitement_PIREN/001_6H55_ortho_UTM31N_IR.tif\"\n",
    "print(\"fileout IR :\",fileout_IR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO :\n",
    "1. Resampling du cluster : JE pars du principr qu'on utilise seulement celle sur HSV ?? malgré que VIS isole bien les plaques (DONE)___\n",
    "        1. Coeff de resampling différent d'une IR à l'autre (DONE)___\n",
    "2. Transformation en DataFrame (DONE)___\n",
    "3. Ajout d'un label Cluster à l'ensemble d'une IR (?? vraiment nécessaire ??)\n",
    "4. Isolation des points autour d'une sonde (deux rayons blablabla)\n",
    "5. On choisi le groupe qui possède la plus grosse proportion dans les points (~1800-2000pts par Pseudo-Temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Re_sampling_function(filetif_dataset,ls_filetif_res,filetif) :\n",
    "    \"\"\"\n",
    "    Re-sampling avec un fichier temporaire \"sampled.tif\" qui permet de faire correspondre deux .tif avec comme\n",
    "    base la résolution (x,y) du pixel\n",
    "    filetif_dataset : chemin d'accès du .tif à re-sampler\n",
    "    filetif_res : chemin d'accès du '.tif' à la résolution (x,y) cible\n",
    "    \n",
    "    \"\"\"\n",
    "    ls_fileout = []\n",
    "    for kk,filetif_res in enumerate(ls_filetif_res) : \n",
    "        ## On récupère la résolution cible\n",
    "        with rio.open(filetif_res) as dataset_res :\n",
    "                #print(\"dataset_res : \",dataset_res.res)\n",
    "                res_x = dataset_res.res[0]\n",
    "                res_y = dataset_res.res[1]\n",
    "\n",
    "        ## On récupère le dataset cible\n",
    "        with rio.open(filetif_dataset) as dataset :\n",
    "                #print(\"dataset : \",dataset.res)\n",
    "                res_dataset_x = dataset.res[0]\n",
    "                res_dataset_y = dataset.res[1]\n",
    "\n",
    "                # Facteurs liés au resampling \n",
    "                upscale_factor_height = res_dataset_y / res_y\n",
    "                upscale_factor_width = res_dataset_x / res_x\n",
    "\n",
    "                # resample data to target shape\n",
    "                data = dataset.read(\n",
    "                    out_shape=(\n",
    "                        dataset.count,\n",
    "                        int(dataset.height * upscale_factor_height),\n",
    "                        int(dataset.width * upscale_factor_width)),\n",
    "                    resampling=Resampling.bilinear\n",
    "                )\n",
    "\n",
    "                # scale image transform\n",
    "                transform = dataset.transform * dataset.transform.scale(\n",
    "                    (dataset.width / data.shape[-1]),\n",
    "                    (dataset.height / data.shape[-2])\n",
    "                )\n",
    "\n",
    "                # Save the new profile & .tif\n",
    "                profile = {\n",
    "                    \"driver\": \"GTiff\",\n",
    "                    \"count\": 1,\n",
    "                    \"height\": int(dataset.height * upscale_factor_height),\n",
    "                    \"width\": int(dataset.width * upscale_factor_width),\n",
    "                    \"dtype\": \"uint8\",\n",
    "                    \"transform\": transform,\n",
    "                    \"bounds\": dataset.bounds,\n",
    "                    \"crs\": dataset.crs,\n",
    "                    \"res\": (transform[0],transform[4])\n",
    "                }\n",
    "                # Filepath \n",
    "                fileout = \"./traitement_PIREN/sampled_\"+str(filetif[kk])+\".tif\"\n",
    "                print(\"new shape :\", data.shape[1:3])\n",
    "                with rio.open(fileout,\"w\",**profile) as dataset_sample :\n",
    "                    dataset_sample.write(data)\n",
    "                    print(\"Completed, new file can be found :\",fileout)\n",
    "                    ls_fileout.append(fileout)\n",
    "                \n",
    "    return ls_fileout\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_pseudo_temp_clust(ls_path_tif,ls_filepath_cluster,dict_IR,r1 = 0.7 , r2 = 1.5) :\n",
    "    \"\"\"\n",
    "    Création d'un dictionnaire classé par IR contenant toutes les données comprise entre un rayon r1 et r2, \n",
    "    \"\"\"\n",
    "    \n",
    "    dict_value_IR = {}\n",
    "\n",
    "    for i,IR in enumerate(dict_IR) :\n",
    "        dict_value_sensor = {}\n",
    "        with rio.open(ls_path_tif[i]) as dataset : # ouverture du fichier obligatoire pour recup la valeur\n",
    "            for sensor in dict_IR[IR][\"dict_windows\"] :\n",
    "\n",
    "                res = dict_IR[IR][\"dict_windows_param\"][sensor][\"resolution\"] # resolution [x,y]\n",
    "                sensor_dataframe = dict_IR[IR][\"dict_windows\"][sensor]\n",
    "                mid_indice = (dict_IR[IR][\"dict_windows_param\"][sensor]['win'].width) # les indices commencent à 0 !\n",
    "\n",
    "                mid_x = sensor_dataframe.iloc[len(sensor_dataframe)//2][\"x\"] \n",
    "                mid_y = sensor_dataframe.iloc[(mid_indice//2)-1][\"y\"]# la valeur du milieu est //2 \n",
    "\n",
    "                #list des valeurs autour de [0, 2pi] , mouvement anti-horaire\n",
    "                theta = np.linspace(0,np.pi*2,round(np.pi*2/res[0]))\n",
    "                ls_x = np.empty([1]) ; ls_y = np.empty([1])\n",
    "\n",
    "                #recherche de points entre deux rayon r1 et r2\n",
    "                \n",
    "                for THETA in theta :\n",
    "                    #\n",
    "                    x1 = mid_x + r1*np.cos(THETA)\n",
    "                    y1 = mid_y + r1*np.sin(THETA)\n",
    "\n",
    "                    x2 = mid_x + r2*np.cos(THETA)\n",
    "                    y2 = mid_y + r2*np.sin(THETA)\n",
    "\n",
    "                    ls_x = np.append(ls_x,np.linspace(x1,x2,round((r2-r1)/res[0])+1)) \n",
    "                    ls_y = np.append(ls_y,np.linspace(y1,y2,round((r2-r1)/res[1])+1))\n",
    "\n",
    "                ls_x = np.delete(ls_x,0) ; ls_y = np.delete(ls_y,0)\n",
    "\n",
    "\n",
    "                with rio.open(ls_filepath_cluster[i]) as dataset_cluster : # ouverture du fichier obligatoire pour recup la valeur\n",
    "\n",
    "                    dict_IR[IR][\"dict_windows_param\"][sensor]['win'].width # résolution -> nb de pixel == nb d'indice \n",
    "                    ls_cluster = []\n",
    "                    ls_value   = []\n",
    "                    for k in range(len(ls_x)) :\n",
    "\n",
    "                        for value in dataset_cluster.sample([(float(ls_x[k]),float(ls_y[k]))]) : \n",
    "                            ls_cluster.append(float(value))\n",
    "                        \n",
    "                        for value in dataset.sample([(float(ls_x[k]),float(ls_y[k]))]) : \n",
    "                            ls_value.append(float(value))\n",
    "\n",
    "                    dict_value_sensor[sensor] = pd.DataFrame(\n",
    "                        np.array([ls_x,ls_y,ls_cluster,ls_value],\n",
    "                                 dtype = float).T,columns = [\"x\",\"y\",\"cluster\",\"value\"])\n",
    "        print(IR)\n",
    "        dict_value_IR[IR] = dict_value_sensor\n",
    "        print(\"nombre de coordonnées utilisée pour la moyenne :\",dict_value_IR[IR][sensor].shape[0])\n",
    "        \n",
    "    return dict_value_IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pseudo_temp_clust(dict_value_IR,ls_fileout) :\n",
    "    \"\"\"\n",
    "    Fonction qui permet d'établir les valeurs de Pseudo-température à l'aide des clusters, \n",
    "    La pseudo-temp correspond à la valeur moyenne du cluster comportant le plus de pixel autout d'une sonde\n",
    "    \"\"\"\n",
    "    \n",
    "    requested_sonde = ['S1', 'S10', 'S2', 'S3-AIR', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9']\n",
    "    pseudo_temp = {}\n",
    "    \n",
    "    for sonde in requested_sonde :\n",
    "        pseudo_temp_IR = {}\n",
    "        for IR in dict_value_IR :\n",
    "            print(IR)\n",
    "            df = dict_value_IR[IR][sonde]\n",
    "            last_count = 0\n",
    "            clust_group = 0\n",
    "            for ii in np.arange(df[\"cluster\"].min(),df[\"cluster\"].max()+1) : \n",
    "                count = len(df[\"cluster\"].loc[df[\"cluster\"]== int(ii)].values)\n",
    "                if count > last_count :\n",
    "                    count = last_count\n",
    "                    clust_group = ii\n",
    "            \n",
    "            \n",
    "            var = df.loc[df[\"cluster\"]== int(ii)][\"value\"].std()\n",
    "            mean = df.loc[df[\"cluster\"]== int(ii)][\"value\"].mean()\n",
    "            print(sonde,IR,\"mean :\",mean)\n",
    "            pseudo_temp_IR[IR] = {\"values\" : mean,\n",
    "                                  \"var\" : var,\n",
    "                                  \"time\" : np.NAN }\n",
    "            #print(\"var :\",pseudo_temp_IR[IR]['var'])\n",
    "\n",
    "            pseudo_temp_IR[IR]['time'] = pd.Timestamp(str('2019-04-14' +' '\n",
    "                                                          +IR[IR.find('_')+1:IR.find(('H'))] + ':' + \n",
    "                                                          IR[IR.find('H')+1::] )).round('30min')\n",
    "            \n",
    "        \n",
    "        pseudo_temp[sonde] = pseudo_temp_IR\n",
    "        \n",
    "    for fileout in ls_fileout :\n",
    "        print(\"suppress IR :\",fileout)\n",
    "        rio.shutil.delete(fileout)\n",
    "        \n",
    "    return pseudo_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetif = ['6H55','7H29','8H22','9H28','10H22','11H27','12H31','13H26',\n",
    "                               '15H59','17H27']\n",
    "#filetif = ['6H55']\n",
    "ls_path_tif,filetif = get_tif(filetif)\n",
    "Dimension = 4 # en m\n",
    "\n",
    "## HSV\n",
    "ls_fileout_hsv = Re_sampling_function(fileout_cluster_hsv,ls_path_tif,filetif)\n",
    "#filetif_sampled = list(\"sampled_\"+file for file in filetif)\n",
    "\n",
    "# Dictionnaire fenêtrage autour des sondes \n",
    "dict_IR_hsv = reading_1band(Dimension,filetif,ls_fileout_hsv,LABEL = \"cluster\")\n",
    "# Dictionnaire contenant les valeurs comprise entre les deux rayons de recherche\n",
    "dict_value_hsv = get_value_pseudo_temp_clust(ls_path_tif,ls_fileout_hsv,dict_IR_hsv,r1 = 0.7 , r2 = 1.5)\n",
    "# Dictionnaire contenant les valeurs pseudo-température\n",
    "pseudo_temp = evaluate_pseudo_temp_clust(dict_value_hsv,ls_fileout_hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pseudo_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sonde in [\"S1\"] :\n",
    "        pseudo_temp_IR = {}\n",
    "        for IR in [\"IR_6H55\"] :\n",
    "            print(IR)\n",
    "            df = dict_value_hsv[IR][sonde]\n",
    "            last_count = 0\n",
    "            clust_group = 0\n",
    "            for ii in np.arange(df[\"cluster\"].min(),df[\"cluster\"].max()+1) : \n",
    "                count = len(df[\"cluster\"].loc[df[\"cluster\"]== int(ii)].values)\n",
    "                if count > last_count :\n",
    "                    count = last_count\n",
    "                    clust_group = ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTIE GRAPHIQUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot : normalization différente pour chaque IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot de plusieurs sondes sans patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "requested_sensor = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\"]\n",
    "fig,ax = plt.subplots(len(requested_sensor),1,figsize=(20,30))\n",
    "for k,sensor in enumerate(requested_sensor) :\n",
    "    with sns.color_palette(\"husl\") as cmap :\n",
    "        data = dict_sensor[sensor]\n",
    "\n",
    "        ax[k].set_ylim(0, 1)\n",
    "        sns.boxplot(x='IR',y=\"band 1\",\n",
    "                   data = data,palette = cmap , ax = ax[k])\n",
    "        sns.set_theme(style=\"ticks\",font_scale = 2)\n",
    "\n",
    "        sns.despine(offset=10, trim=True)\n",
    "        \n",
    "        ax[k].set_title(sensor)\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None ,wspace=None, hspace=0.8)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot d'une sonde accompagné des patchs IR et IR normalisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "requested_sensor = [\"S3-AIR\"]\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "\n",
    "gs = GridSpec(3, 10, figure=fig)\n",
    "gs.update(wspace = 0.4, hspace=0.0) # set the spacing between axes.\n",
    "\n",
    "for sensor in requested_sensor :\n",
    "    with sns.color_palette(\"husl\") as cmap :\n",
    "        data = dict_sensor[sensor]\n",
    "        \n",
    "        ax = fig.add_subplot(gs[0, :])\n",
    "        \n",
    "        ax.set_ylim(0,1)\n",
    "        sns.boxplot(x='IR',y=\"band 1\",\n",
    "                   data = data,palette = cmap,ax = ax )\n",
    "        sns.set_theme(style=\"ticks\",font_scale = 2)\n",
    "        sns.despine(offset=10, trim=True)\n",
    "        LONGUEUR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][\"S10\"][\"LONGUEUR\"]\n",
    "        \n",
    "        ax.set_ylabel(\"Normalisation commune\",fontsize = 20)\n",
    "        plt.title(sensor + ' '+str(LONGUEUR)+ 'm patch')\n",
    "        \n",
    "        for k,IR in enumerate(dict_IR) :\n",
    "            ax2 = fig.add_subplot(gs[1, k])\n",
    "            band_min = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"all_band\"].min()\n",
    "            band_max = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"all_band\"].max()\n",
    "            \n",
    "            window_IR_Normalize = ((dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"all_band\"]-band_min)/(band_max-band_min)) \n",
    "            window_transform_IR = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"win_transform\"]\n",
    "            extent = plotting_extent(window_IR_Normalize,window_transform_IR)\n",
    "            sub_fig = ax2.imshow(window_IR_Normalize,extent = extent,cmap ='viridis',vmin = 0,vmax = 1)\n",
    "            ax2.set_title(IR)\n",
    "            ax2.set_xticks([])\n",
    "            ax2.set_yticks([])\n",
    "            fig.colorbar(sub_fig,ax=ax2,fraction=0.046, pad=0.04)\n",
    "            \n",
    "            ax3 = fig.add_subplot(gs[2, k])\n",
    "            window_IR = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"all_band\"]\n",
    "            window_transform_IR = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"win_transform\"]\n",
    "            extent = plotting_extent(window_IR,window_transform_IR)\n",
    "            sub_fig2 = ax3.imshow(window_IR,extent = extent,cmap ='viridis')\n",
    "            fig.colorbar(sub_fig2,ax=ax3,fraction=0.046, pad=0.04)\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot : normalization commune des IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot de plusieurs sondes sans patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "requested_sensor = [\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]\n",
    "fig,ax = plt.subplots(len(requested_sensor),1,figsize=(20,30))\n",
    "for k,sensor in enumerate(requested_sensor) :\n",
    "    with sns.color_palette(\"husl\") as cmap :\n",
    "        \n",
    "        data = dict_sensor[sensor]\n",
    "\n",
    "        ax[k].set_ylim(0, 1)\n",
    "        sns.boxplot(x='IR',y=\"band N\",\n",
    "                   data = data,palette = cmap,ax = ax[k] )\n",
    "        sns.set_theme(style=\"ticks\",font_scale = 2)\n",
    "        \n",
    "        ax[k].set_ylabel(\"Normalisation commune\",fontsize = 20)\n",
    "        ax[k].set_title(sensor)\n",
    "        \n",
    "        sns.despine(offset=10, trim=True)\n",
    "        \n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None ,wspace=None, hspace=0.8)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot d'une sonde accompagné des patchs IR et IR normalisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "requested_sensor = [\"S10\"]\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "\n",
    "gs = GridSpec(3, 10, figure=fig)\n",
    "gs.update(wspace = 0.4, hspace=0.0) # set the spacing between axes.\n",
    "\n",
    "            \n",
    "for sensor in requested_sensor :\n",
    "    # Valeurs requises pour la normalisation \n",
    "    BAND_MIN_N = 0\n",
    "    BAND_MAX_N = 0\n",
    "    \n",
    "    for target in dict_IR :\n",
    "        min_= dict_IR[target][\"dict_windows\"][sensor][\"band 1\"].min()\n",
    "        max_= dict_IR[target][\"dict_windows\"][sensor][\"band 1\"].max()\n",
    "        if min_ < BAND_MIN_N :\n",
    "            BAND_MIN_N = min_\n",
    "\n",
    "\n",
    "        if max_ > BAND_MAX_N :\n",
    "            BAND_MAX_N = max_\n",
    "    \n",
    "    print(\"BAND_MIN_N\",BAND_MIN_N) # valeur minimale retenue pour la normalisation\n",
    "    print(\"BAND_MAX_N\",BAND_MAX_N) # valeur maximale retenue pour la normalisation\n",
    "    \n",
    "    with sns.color_palette(\"husl\") as cmap :\n",
    "        data = dict_sensor[sensor]\n",
    "        \n",
    "        ax = fig.add_subplot(gs[0, :])\n",
    "        \n",
    "        ax.set_ylim(0,1)\n",
    "        sns.boxplot(x='IR',y=\"band N\",\n",
    "                   data = data,palette = cmap,ax = ax )\n",
    "        sns.set_theme(style=\"ticks\",font_scale = 2)\n",
    "        sns.despine(offset=10, trim=True)\n",
    "        LONGUEUR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][\"S10\"][\"LONGUEUR\"]\n",
    "        \n",
    "        ax.set_ylabel(\"Normalisation commune\",fontsize = 20)\n",
    "        plt.title(sensor + ' '+str(LONGUEUR)+ 'm patch')\n",
    "        \n",
    "        # Plot des IRs Normalisées et Non Normalisées\n",
    "        for k,IR in enumerate(dict_IR) :\n",
    "            ax2 = fig.add_subplot(gs[1, k])\n",
    "            window_IR_Normalize = ((dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"all_band\"]-BAND_MIN_N)/(BAND_MAX_N-BAND_MIN_N)) \n",
    "            window_transform_IR = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"win_transform\"]\n",
    "            extent = plotting_extent(window_IR_Normalize,window_transform_IR)\n",
    "            sub_fig = ax2.imshow(window_IR_Normalize,extent = extent,cmap ='viridis',vmin = 0,vmax = 1)\n",
    "            ax2.set_title(IR)\n",
    "            ax2.set_xticks([ ])\n",
    "            ax2.set_yticks([ ])\n",
    "            fig.colorbar(sub_fig,ax=ax2,fraction=0.046, pad=0.04)\n",
    "            \n",
    "            ax3 = fig.add_subplot(gs[2, k])\n",
    "            window_IR = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"all_band\"]\n",
    "            window_transform_IR = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"win_transform\"]\n",
    "            extent = plotting_extent(window_IR,window_transform_IR)\n",
    "            sub_fig2 = ax3.imshow(window_IR,extent = extent,cmap ='viridis')\n",
    "            fig.colorbar(sub_fig2,ax=ax3,fraction=0.046, pad=0.04)\n",
    "\n",
    "fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/Normalisation commune/\"+ str(sensor)+\".png\"\n",
    "fig.savefig(fileout,bbox_inches = 'tight')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Liste de keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_IR.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_IR['IR_6H55'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_IR['IR_6H55'][\"dict_windows_param\"][\"S10\"].keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot d'une sonde + Pseudo Temp° + IR + Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_sensor = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "requested_sensor = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]\n",
    "#n = dict_windows_param_cluster_hsv[sensor][\"all_band\"].max()\n",
    "n = 6\n",
    "for sensor in requested_sensor :\n",
    "    \n",
    "    # Propriétés graphiques\n",
    "    fig = plt.figure(figsize=(25,15))\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 12\n",
    "    BIGGER_SIZE = 15\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    ##Création des figures\n",
    "    gs = GridSpec(3, 10, figure=fig)\n",
    "    gs.update(wspace = 0.5, hspace=0.0) # set the spacing between axes.\n",
    "    ax = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    ls_values = [] # listes des valeurs\n",
    "    ls_time   = [] # listes des temps \n",
    "    ls_var    = [] # listes des écarts-types\n",
    "    rms       = [] # listes des RMS\n",
    "    \n",
    "    print(sensor)\n",
    "    for IR in dict_value_IR :\n",
    "        ls_values.append(pseudo_temp[sensor][IR][\"values\"])\n",
    "        ls_time.append(pseudo_temp[sensor][IR][\"time\"])\n",
    "        ls_var.append(pseudo_temp[sensor][IR][\"var\"])\n",
    "        \n",
    "\n",
    "    \n",
    "    SLICE = dict_temp_sensor[sensor]\n",
    "    ## Plot de la température des sondes \n",
    "    plottingtemp_single_label_IR_a(SLICE,fig,ax,'T4',200,6)\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax3 = ax.twinx() # instantiate a second axes that shares the same x-axis\n",
    "    color = \"tab:red\"\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax.grid()\n",
    "\n",
    "    ## Plot de la pseudo Température \n",
    "    ax3.plot(ls_time,ls_values,color = color)\n",
    "    ax3.plot(ls_time,ls_values,'ro',color = color)\n",
    "    ax3.tick_params(axis = 'y', labelcolor = color)\n",
    "    ax3.set_ylabel(\"Pseudo Température\", color = color, fontsize = 20)\n",
    "    ax3.set_ylim(-5,30)\n",
    "    \n",
    "    # [ val - sigma , val + sigma]\n",
    "    \n",
    "    ls_sigma = [np.array(ls_values)-np.array(ls_var),np.array(ls_values)+np.array(ls_var)]\n",
    "    \n",
    "    ## Affichage des valeurs de RMS\n",
    "    for w in range(len(ls_time)) :\n",
    "        y_actual    = SLICE.loc[SLICE[\"Time\"]==ls_time[w]][\"T4\"] \n",
    "        y_predicted = ls_values[w]\n",
    "        rms.append(np.absolute(np.mean(y_actual-y_predicted)))\n",
    "        ax3.text(ls_time[w],ls_values[w]+0.5,str(rms[w])[0:5],fontsize = 15) # valeurs RMS\n",
    "  \n",
    "    ## Affichage de la valeur de RMSE (une valeur)\n",
    "    ls_slice_value = []\n",
    "    for time in ls_time : # compare uniquement les pseudo-temp et les valeurs de sonde \n",
    "        ls_slice_value.append(float(SLICE[\"T4\"].loc[SLICE['Time'] == time]))\n",
    "    \n",
    "    RMSE = mean_squared_error(ls_slice_value,ls_values,squared=False)\n",
    "    ax3.text(SLICE[\"Time\"].iloc[-8],28,'RMSE = ' + str(RMSE)[0:5],fontsize = 15) # valeurs RMSE\n",
    "    \n",
    "    # Interval de confiance +/- sigma \n",
    "    ax3.plot(ls_time,ls_sigma[0],'m',linestyle='--',label = '- sigma') # value - sigma\n",
    "    ax3.plot(ls_time,ls_sigma[1],'m',linestyle='--',label = '+ sigma') # value + sigma\n",
    "    ax3.legend(loc='upper right', bbox_to_anchor=(1, 0.80))\n",
    "    \n",
    "    ## plot des patchs IRs\n",
    "    for k,IR in enumerate(dict_IR) :\n",
    "        ax2 = fig.add_subplot(gs[1, k])\n",
    "        \n",
    "        window_IR = dict_IR[IR][\"dict_windows_param\"][sensor][\"all_band\"]\n",
    "        window_transform_IR = dict_IR[IR][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "        extent = plotting_extent(window_IR,window_transform_IR)\n",
    "        \n",
    "        sub_fig = ax2.imshow(window_IR,extent = extent,cmap ='viridis')\n",
    "        ax2.set_title(IR,fontsize = 20,pad = 20)\n",
    "        fig.colorbar(sub_fig,ax=ax2,fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Plot des targets\n",
    "        TARGET = sensor_coord.loc[sensor_coord[\"SensorName\"]==sensor]\n",
    "        c_1 = dict_value_IR[IR][sensor][\"x\"].iloc[0]\n",
    "        c_2 = dict_value_IR[IR][sensor][\"x\"].iloc[-1]\n",
    "        X = np.array(TARGET[\"x\"],dtype = float)\n",
    "        Y = np.array(TARGET[\"y\"],dtype=float)\n",
    "        circle1 = plt.Circle((X,Y),(c_1-X),color='b', fill=False)\n",
    "        circle2 = plt.Circle((X,Y),(c_2-X),color='r', fill=False)\n",
    "        ax2.add_patch(circle1)\n",
    "        ax2.add_patch(circle2)\n",
    "      \n",
    "    ## plot des labels de clustering \n",
    "    #visible\n",
    "    ax4 = fig.add_subplot(gs[2, 0:2])\n",
    "    #n = dict_windows_param_cluster[sensor][\"all_band\"].max()\n",
    "    ole=cm.get_cmap('jet', n)\n",
    "    \n",
    "    window_cluster = dict_windows_param_cluster[sensor][\"all_band\"]\n",
    "    window_cluster_transform = dict_windows_param_cluster[sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_cluster,window_cluster_transform)\n",
    "    sub_fig = ax4.imshow(window_cluster,extent = extent,cmap = ole,vmin = 0,vmax = n)\n",
    "    ax4.set_title(sensor + \" cluster sur la bande visible\",fontsize = 20,pad = 20)\n",
    "    fig.colorbar(sub_fig,ax=ax4,fraction=0.046, pad=0.04)\n",
    "    \n",
    "    #hsv\n",
    "    ax5 = fig.add_subplot(gs[2, 7:-1])\n",
    "    window_hsv = dict_windows_param_cluster_hsv[sensor][\"all_band\"]\n",
    "    window_transform_hsv = dict_windows_param_cluster_hsv[sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_hsv,window_transform_hsv)\n",
    "    sub_fig = ax5.imshow(window_hsv,extent = extent,cmap = ole,vmin = 0,vmax = n)\n",
    "    ax5.set_title(sensor + \" cluster sur la bande HSV\",fontsize = 20,pad = 20)\n",
    "    fig.colorbar(sub_fig,ax=ax5,fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ## plot du patch visible\n",
    "    ax6 = fig.add_subplot(gs[2, 3:6])\n",
    "    window_vis = dict_windows_param[sensor][\"all_band\"]\n",
    "    window_transform_vis = dict_windows_param[sensor][\"win_transform\"]\n",
    "    show(window_vis,transform = window_transform_vis,ax = ax6)\n",
    "    ax6.set_title(' ',fontsize = 20,pad = 20)\n",
    "    \n",
    "    ## paramètres d'affichage\n",
    "    ax.set_title(sensor +\" et valeurs de RMS pour chaque pseudo température\",fontsize = 20)\n",
    "    ax.set_xticklabels([str(time.hour)+':'+str(time.minute) for time in SLICE['Time']][::8])\n",
    "    ax.set_xlabel('Time (heures:minutes)' + ' 2019-04-19' )\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/\"+ str(sensor)+\".png\"\n",
    "    fig.savefig(fileout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courbe de différence pour toutes les sondes ( Temp° sonde - Pseudo_Temp° )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour toutes les courbes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "requested_sensor = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]\n",
    "\n",
    "coloration=plt.cm.tab10(np.linspace(0,1,10))\n",
    "fig,ax = plt.subplots(1,figsize=(30,10))\n",
    "\n",
    "\n",
    "\n",
    "for k,sensor in enumerate(requested_sensor) :\n",
    "    \n",
    "    # Propriétés graphiques\n",
    "    \n",
    "    SMALL_SIZE = 15\n",
    "    MEDIUM_SIZE = 15\n",
    "    BIGGER_SIZE = 30\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    ls_values = [] # listes des valeurs\n",
    "    ls_time   = [] # listes des temps \n",
    "    ls_var    = [] # listes des écarts-types\n",
    "    rms       = [] # listes des RMS\n",
    "    ls_slice_value = []\n",
    "    \n",
    "    \n",
    "    print(sensor)\n",
    "    for IR in dict_value_IR :\n",
    "        ls_values.append(pseudo_temp[sensor][IR][\"values\"])\n",
    "        ls_time.append(pseudo_temp[sensor][IR][\"time\"])\n",
    "        ls_var.append(pseudo_temp[sensor][IR][\"var\"])\n",
    "        \n",
    "    SLICE = dict_temp_sensor[sensor]\n",
    "    ## Affichage des valeurs de RMS\n",
    "    for w in range(len(ls_time)) :\n",
    "        y_actual    = SLICE.loc[SLICE[\"Time\"]==ls_time[w]][\"T4\"]\n",
    "        y_predicted = ls_values[w]\n",
    "        rms.append(np.mean(y_actual-y_predicted))\n",
    "    \n",
    "    # Affichage des valeurs de RMSE\n",
    "    for time in ls_time : # compare uniquement les pseudo-temp et les valeurs de sonde \n",
    "        ls_slice_value.append(float(SLICE[\"T4\"].loc[SLICE['Time'] == time]))\n",
    "    RMSE = mean_squared_error(ls_slice_value,ls_values,squared=False)\n",
    "    dict_rms[sensor] = {\"RMS\" : rms , \"Time\" : ls_time ,\"RMSE\" : RMSE }\n",
    "    \n",
    "    ax.plot(ls_time,rms,color=coloration[k,:],label = sensor +', RMSE : '+ str(RMSE)[0:5]) \n",
    "    ax.plot(ls_time,rms,'o',color=coloration[k,:])\n",
    "    \n",
    "ax.set_xticks(ls_time)\n",
    "ax.set_xticklabels([str(time.hour)+':'+str(time.minute) for time in ls_time])\n",
    "ax.set_xlabel('Time (heures:minutes)' + ' 2019-04-19' )\n",
    "ax.set_ylabel('Temp [C]')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_title(\"Courbes des différences entre les valeus de T° et des Pseudo T° \")\n",
    "                   \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthodes d'interpolation des pseudo-températures pour sonde(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "for sensor in dict_sensor :\n",
    "    x = [(times.minute + times.hour * 60) for times in dict_rms[sensor][\"Time\"]]\n",
    "    y = dict_rms[sensor][\"pseudo_temp\"]\n",
    "    fig,ax = plt.subplots(1,figsize=(15,5))\n",
    "    \n",
    "\n",
    "    ls_kind = [\"zero\",\"slinear\",\"quadratic\",\"cubic\"]\n",
    "    color = ['gold','cyan',\"chartreuse\",\"dodgerblue\"]\n",
    "    for k,kind in enumerate(ls_kind) :\n",
    "        start = dict_rms[sensor][\"Time\"][0]\n",
    "        end = dict_rms[sensor][\"Time\"][-1]\n",
    "\n",
    "        f = interp1d(x,y,kind =kind)\n",
    "        xnew = [(times.minute + times.hour * 60) for times in pd.date_range(start,end,freq = \"15min\")]\n",
    "        # création d'une valeur toutes les 15 minutes\n",
    "        ynew = f(xnew)\n",
    "        ax.plot(xnew,ynew,color = color[k],label = kind + ' ('+str(k)+' ordre)')\n",
    "\n",
    "    ax.plot(x,y,'ro',label = \"data\")\n",
    "    ax.set_xticklabels([str(time.hour)+':'+str(time.minute) for time in dict_rms[sensor][\"Time\"]])\n",
    "    ax.set_xlabel('Time (heures:minutes)' + ' 2019-04-19' )\n",
    "    ax.set_ylabel('Temp [C]')\n",
    "    plt.legend()\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax.set_title(\"Méthodes d'interpolation des pseudo-température pour la sonde \"+sensor)\n",
    "    ax.grid()\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/debut_interpolation/\"+ str(sensor)+\".png\"\n",
    "    fig.savefig(fileout,bbox_inches = 'tight' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "for sensor in dict_sensor :\n",
    "    x = [(times.minute + times.hour * 60) for times in dict_rms[sensor][\"Time\"]]\n",
    "    y = dict_rms[sensor][\"RMS\"]\n",
    "    fig,ax = plt.subplots(1,figsize=(15,5))\n",
    "    \n",
    "\n",
    "    ls_kind = [\"zero\",\"slinear\",\"quadratic\",\"cubic\"]\n",
    "    color = ['gold','cyan',\"chartreuse\",\"dodgerblue\"]\n",
    "    for k,kind in enumerate(ls_kind) :\n",
    "        start = dict_rms[sensor][\"Time\"][0]\n",
    "        end = dict_rms[sensor][\"Time\"][-1]\n",
    "\n",
    "        f = interp1d(x,y,kind =kind)\n",
    "        xnew = [(times.minute + times.hour * 60) for times in pd.date_range(start,end,freq = \"15min\")]\n",
    "        # création d'une valeur toutes les 15 minutes\n",
    "        ynew = f(xnew)\n",
    "        ax.plot(xnew,ynew,color = color[k],label = kind + ' ('+str(k)+' ordre)')\n",
    "\n",
    "    ax.plot(x,y,'ro',label = \"data\")\n",
    "    ax.set_xticklabels([str(time.hour)+':'+str(time.minute) for time in dict_rms[sensor][\"Time\"]])\n",
    "    ax.set_xlabel('Time (heures:minutes)' + ' 2019-04-19' )\n",
    "    ax.set_ylabel('Temp [C]')\n",
    "    plt.legend()\n",
    "    ax.set_title(\"Méthodes d'interpolation des différences de pseudo-température pour la sonde \"+sensor)\n",
    "    ax.grid()\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/debut_interpolation/\"+ str(sensor)+\"_difference.png\"\n",
    "    fig.savefig(fileout,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot de la PT + IR + IR calibrée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_sensor = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]\n",
    "for sensor in requested_sensor :\n",
    "    \n",
    "    # Propriétés graphiques\n",
    "    fig = plt.figure(figsize=(25,15))\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 12\n",
    "    BIGGER_SIZE = 15\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    ##Création des figures\n",
    "    gs = GridSpec(3, 10, figure=fig)\n",
    "    gs.update(wspace = 0.3, hspace=0.0) # set the spacing between axes.\n",
    "    ax = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    \n",
    "    ls_values = [] # listes des valeurs\n",
    "    ls_time   = [] # listes des temps \n",
    "    ls_var    = [] # listes des écarts-types\n",
    "    rms       = [] # listes des RMS\n",
    "    \n",
    "    print(sensor)\n",
    "    for IR in dict_value_IR :\n",
    "        ls_values.append(pseudo_temp[sensor][IR][\"values\"])\n",
    "        ls_time.append(pseudo_temp[sensor][IR][\"time\"])\n",
    "        ls_var.append(pseudo_temp[sensor][IR][\"var\"])\n",
    "    \n",
    "    SLICE = dict_temp_sensor[sensor]\n",
    "    ## Plot de la température des sondes \n",
    "    plottingtemp_single_label_IR_a(SLICE,fig,ax,'T4',200,6)\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax3 = ax.twinx() # instantiate a second axes that shares the same x-axis\n",
    "    color = \"tab:red\"\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax.grid()\n",
    "\n",
    "    ## Plot de la pseudo Température \n",
    "    ax3.plot(ls_time,ls_values,color = color)\n",
    "    ax3.plot(ls_time,ls_values,'ro',color = color)\n",
    "    ax3.tick_params(axis = 'y', labelcolor = color)\n",
    "    ax3.set_ylabel(\"Pseudo Température\", color = color, fontsize = 20)\n",
    "    ax3.set_ylim(-5,30)\n",
    "    \n",
    "    # [ val - sigma , val + sigma]\n",
    "    \n",
    "    ls_sigma = [np.array(ls_values)-np.array(ls_var),np.array(ls_values)+np.array(ls_var)]\n",
    "    \n",
    "    ## Affichage des valeurs de RMS\n",
    "    for w in range(len(ls_time)) :\n",
    "        y_actual    = SLICE.loc[SLICE[\"Time\"]==ls_time[w]][\"T4\"] \n",
    "        y_predicted = ls_values[w]\n",
    "        rms.append(np.absolute(np.mean(y_actual-y_predicted)))\n",
    "        ax3.text(ls_time[w],ls_values[w]+0.5,str(rms[w])[0:5],fontsize = 15) # valeurs RMS\n",
    "  \n",
    "    ## Affichage de la valeur de RMSE (une valeur)\n",
    "    ls_slice_value = []\n",
    "    for time in ls_time : # compare uniquement les pseudo-temp et les valeurs de sonde \n",
    "        ls_slice_value.append(float(SLICE[\"T4\"].loc[SLICE['Time'] == time]))\n",
    "    \n",
    "    RMSE = mean_squared_error(ls_slice_value,ls_values,squared=False)\n",
    "    ax3.text(SLICE[\"Time\"].iloc[-8],28,'RMSE = ' + str(RMSE)[0:5],fontsize = 15) # valeurs RMSE\n",
    "    \n",
    "    # Interval de confiance +/- sigma \n",
    "    ax3.plot(ls_time,ls_sigma[0],'k',linestyle='--',label = '- sigma') # value - sigma\n",
    "    ax3.plot(ls_time,ls_sigma[1],'k',linestyle='--',label = '+ sigma') # value + sigma\n",
    "    ax3.legend(loc='upper right', bbox_to_anchor=(1, 0.80))\n",
    "    \n",
    "    # plot des target IR Calibrée / Non Calibrée\n",
    "    for k,IR in enumerate(dict_IR) :\n",
    "        \n",
    "        ax2 = fig.add_subplot(gs[1, k])\n",
    "        window_IR = dict_IR[IR][\"dict_windows_param\"][sensor][\"all_band\"]\n",
    "        window_transform_IR = dict_IR[IR][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "        extent = plotting_extent(window_IR,window_transform_IR)\n",
    "\n",
    "        sub_fig = ax2.imshow(window_IR,extent = extent,cmap ='viridis')\n",
    "        ax2.set_title(IR + ' non calibrée',fontsize = 10,pad = 25)\n",
    "        cbar = fig.colorbar(sub_fig,ax=ax2,fraction=0.046, pad=0.04)\n",
    "        cbar.minorticks_on()\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "        ax2.set_xticks([ ])\n",
    "        ax2.set_yticks([ ])\n",
    "        \n",
    "        # Valeurs calibrées \n",
    "        ax4 = fig.add_subplot(gs[2, k])\n",
    "        window_IR_calibration = dict_IR[IR][\"dict_windows_param\"][sensor][\"calibration\"]\n",
    "        window_transform_IR_calibration = dict_IR[IR][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "        extent_calibration = plotting_extent(window_IR_calibration,window_transform_IR_calibration)\n",
    "\n",
    "        sub_fig = ax4.imshow(window_IR_calibration,extent = extent_calibration,cmap ='viridis')\n",
    "        ax4.set_title(IR + ' CALIBREE',fontsize = 10,pad = 25)\n",
    "        cbar = fig.colorbar(sub_fig,ax=ax4,fraction=0.046, pad=0.04)\n",
    "        cbar.minorticks_on()\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "        ax4.set_xticks([ ])\n",
    "        ax4.set_yticks([ ])\n",
    "    plt.subplots_adjust(wspace=0.01,hspace=-0.7)\n",
    "    ax.set_xticklabels([str(time.hour)+':'+str(time.minute) for time in dict_rms[sensor][\"Time\"]])\n",
    "    ax.set_xlabel('Time (heures:minutes)' + ' 2019-04-19' )\n",
    "    ax.set_ylabel('Temp [C]')\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/calibration/\"+ str(sensor)+\"_calibration.png\"\n",
    "    fig.savefig(fileout,bbox_inches = 'tight' )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de l'IR 7h15 pour toutes les sondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "fig = plt.figure(figsize=(32,15))\n",
    "\n",
    "gs = GridSpec(4, 10, figure=fig)\n",
    "gs.update(wspace = 0.5, hspace=0.0) # set the spacing between axes.\n",
    "\n",
    "            \n",
    "for k,sensor in enumerate(dict_sensor) :\n",
    "\n",
    "    ax2 = fig.add_subplot(gs[0, k])\n",
    "    window_IR_1 = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"calibration\"]\n",
    "    window_transform_IR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_IR_1,window_transform_IR)\n",
    "    MIN = np.nanmin(dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"calibration\"])\n",
    "    MAX = np.nanmax(dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"calibration\"])\n",
    "    \n",
    "    sub_fig = ax2.imshow(window_IR_1,extent = extent,cmap ='viridis',vmin = MIN,vmax = MAX)\n",
    "    ax2.set_title(sensor + ' ' +\"IR_6H55\", pad = 0.5 )\n",
    "    ax2.set_xticks([ ])\n",
    "    ax2.set_yticks([ ])\n",
    "    cbar = fig.colorbar(sub_fig,ax=ax2,fraction=0.046, pad=0.04)\n",
    "    cbar.minorticks_on()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[1, k])\n",
    "    window_IR_interpoled = dict_IR_calibration['IR_7H15'][\"calibration_array\"][sensor]\n",
    "    window_transform_IR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_IR_interpoled,window_transform_IR)\n",
    "    sub_fig2 = ax3.imshow(window_IR_interpoled,extent = extent,cmap ='viridis',vmin = MIN,vmax = MAX)\n",
    "    cbar = fig.colorbar(sub_fig2,ax=ax3,fraction=0.046, pad=0.04)\n",
    "    cbar.minorticks_on()\n",
    "    ax3.set_title(sensor + ' ' +\"IR_7H15\", pad = 0.5 )\n",
    "    ax3.set_xticks([ ])\n",
    "    ax3.set_yticks([ ])\n",
    "    \n",
    "    ax5 = fig.add_subplot(gs[2, k])\n",
    "    window_IR_interpoled = dict_IR_calibration['IR_7H15_2'][\"calibration_array\"][sensor]\n",
    "    window_transform_IR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_IR_interpoled,window_transform_IR)\n",
    "    sub_fig2 = ax5.imshow(window_IR_interpoled,extent = extent,cmap ='viridis',vmin = MIN,vmax = MAX)\n",
    "    cbar = fig.colorbar(sub_fig2,ax=ax5,fraction=0.046, pad=0.04)\n",
    "    cbar.minorticks_on()\n",
    "    ax5.set_title(sensor + ' ' +\"IR_7H15_2\", pad = 0.5 )\n",
    "    ax5.set_xticks([ ])\n",
    "    ax5.set_yticks([ ])\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[3, k])\n",
    "    window_IR = dict_IR[\"IR_7H29\"][\"dict_windows_param\"][sensor][\"calibration\"]\n",
    "    window_transform_IR = dict_IR['IR_7H29'][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_IR,window_transform_IR)\n",
    "    sub_fig = ax4.imshow(window_IR,extent = extent,cmap ='viridis',vmin = MIN,vmax = MAX)\n",
    "    ax4.set_title(sensor + ' ' +\"IR_7H29\" , pad = 0.5 )\n",
    "    ax4.set_xticks([ ])\n",
    "    ax4.set_yticks([ ])\n",
    "    cbar = fig.colorbar(sub_fig,ax=ax4,fraction=0.046, pad=0.04)\n",
    "    cbar.minorticks_on()\n",
    "\n",
    "#fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/Normalisation commune/\"+ str(sensor)+\".png\"\n",
    "#fig.savefig(fileout,bbox_inches = 'tight')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmax(dict_IR[\"IR_6H55\"][\"dict_windows_param\"][\"S1\"][\"calibration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimination des valeurs proche de la plaque en np.NaN : Visualisation\n",
    "### Sauf S3-AIR et S10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot de toutes les IR pour une sonde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_sensor = [\"S1\"]\n",
    "\n",
    "fig1 = plt.figure(figsize=(32,25))\n",
    "\n",
    "gs1 = GridSpec(1, 10, figure=fig)\n",
    "gs1.update(wspace = 0.5, hspace=0.0) # set the spacing between axes.\n",
    "\n",
    "for sensor in requested_sensor :\n",
    "    for k,IR in enumerate(dict_IR) :\n",
    "        ax2 = fig1.add_subplot(gs1[0, k])\n",
    "\n",
    "        window_IR = dict_IR[IR][\"dict_windows_param\"][sensor][\"all_band\"]\n",
    "        window_transform_IR = dict_IR[IR][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "        extent = plotting_extent(window_IR,window_transform_IR)\n",
    "\n",
    "        sub_fig = ax2.imshow(window_IR,extent = extent,cmap ='viridis')\n",
    "        ax2.set_title(IR,pad = 20)\n",
    "        fig1.colorbar(sub_fig,ax=ax2,fraction=0.046, pad=0.04)\n",
    "        \n",
    "\n",
    "        # Plot des targets\n",
    "        TARGET = sensor_coord.loc[sensor_coord[\"SensorName\"]==sensor]\n",
    "        c_1 = dict_suppress_plaque[IR][sensor][\"x\"].iloc[0]\n",
    "        c_2 = dict_suppress_plaque[IR][sensor][\"x\"].iloc[-1]\n",
    "        X = np.array(TARGET[\"x\"],dtype = float)\n",
    "        Y = np.array(TARGET[\"y\"],dtype=float)\n",
    "        #circle1 = plt.Circle((X,Y),(c_1-X),color='b', fill=False)\n",
    "        #circle2 = plt.Circle((X,Y),(c_2-X),color='r', fill=False)\n",
    "        #ax2.add_patch(circle1)\n",
    "        #ax2.add_patch(circle2)\n",
    "        ax2.set_xticks([ ])\n",
    "        ax2.set_yticks([ ])\n",
    "        #VALUE_TO_SUPPRESS = dict_suppress_plaque[IR][sensor][\"value\"].describe()['25%']\n",
    "        #mask_test = dict_suppress_plaque[IR][sensor][\"value\"] < VALUE_TO_SUPPRESS\n",
    "        #masked_value = dict_suppress_plaque[IR][sensor].loc[mask_test]\n",
    "        #ax2.plot(masked_value[\"x\"],masked_value[\"y\"],\"ro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Une IR et une sonde ( visualisation de la calibration )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = \"S2\"\n",
    "IR = \"IR_6H55\"\n",
    "\n",
    "fig_test,ax_test = plt.subplots()\n",
    "\n",
    "window_IR_1 = dict_IR[IR][\"dict_windows_param\"][sensor][\"calibration\"]\n",
    "window_transform_IR = dict_IR[IR][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "extent = plotting_extent(window_IR_1,window_transform_IR)\n",
    "sub_fig = ax_test.imshow(window_IR_1,extent = extent,cmap ='viridis')\n",
    "cbar = fig_test.colorbar(sub_fig,fraction=0.046, pad=0.04)\n",
    "cbar.minorticks_on()\n",
    "\n",
    "# Plot des targets\n",
    "TARGET = sensor_coord.loc[sensor_coord[\"SensorName\"]==sensor]\n",
    "c_1 = dict_suppress_plaque[IR][sensor][\"x\"].iloc[0]\n",
    "c_2 = dict_suppress_plaque[IR][sensor][\"x\"].iloc[-1]\n",
    "X = np.array(TARGET[\"x\"],dtype = float)\n",
    "Y = np.array(TARGET[\"y\"],dtype=float)\n",
    "circle1 = plt.Circle((X,Y),(c_1-X),color='b', fill=False)\n",
    "circle2 = plt.Circle((X,Y),(c_2-X),color='r', fill=False)\n",
    "ax_test.add_patch(circle1)\n",
    "ax_test.add_patch(circle2)\n",
    "VALUE_TO_SUPPRESS = dict_suppress_plaque[IR][sensor][\"value\"].describe()['50%']\n",
    "mask_test = dict_suppress_plaque[IR][sensor][\"value\"] < VALUE_TO_SUPPRESS\n",
    "masked_value = dict_suppress_plaque[IR][sensor].loc[mask_test]\n",
    "#ax_test.plot(masked_value[\"x\"],masked_value[\"y\"],\"ro\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot + label de clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "requested_sensor = [\"S1\"]\n",
    "\n",
    "#n = dict_windows_param_cluster_hsv[sensor][\"all_band\"].max()\n",
    "\n",
    "n = 7 # !!!!!!!!!!!!!!!!!!\n",
    "\n",
    "for sensor in requested_sensor :\n",
    "    \n",
    "    # Propriétés graphiques\n",
    "    fig = plt.figure(figsize=(30,22))\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 12\n",
    "    BIGGER_SIZE = 15\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    ##Création des figures\n",
    "    gs = GridSpec(2, 10, figure=fig)\n",
    "    gs.update(wspace = 0.0, hspace=0.0) # set the spacing between axes.\n",
    "    \n",
    "    \n",
    "    #### boxplot\n",
    "    ax = fig.add_subplot(gs[0, :])\n",
    "    cmap = sns.color_palette(\"turbo\",n)\n",
    "    data = dict_sensor[sensor]\n",
    "    \n",
    "    #ax.set_ylim(0,1)\n",
    "    sns.boxplot(x='IR',y=\"band N\",\n",
    "               data = data,hue = \"clustering_label_vis\",palette = cmap,ax = ax, hue_order = [0,1,2,3,4,5,6])\n",
    "\n",
    "    sns.set_theme(style=\"ticks\",font_scale = 2)\n",
    "    sns.despine(offset=0, trim=True)\n",
    "    LONGUEUR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"LONGUEUR\"]\n",
    "\n",
    "    ax.set_ylabel(\"Signal IR normalisée\",fontsize = 20)\n",
    "    plt.title(sensor + ' '+str(LONGUEUR)+ 'm patch' + \" normalisée\")\n",
    "        \n",
    "    ## plot des labels de clustering \n",
    "    #visible\n",
    "    ax4 = fig.add_subplot(gs[1, 0:2])\n",
    "    #n = dict_windows_param_cluster[sensor][\"all_band\"].max()\n",
    "    ole=cm.get_cmap('turbo', n)\n",
    "    \n",
    "    window_cluster = dict_windows_param_cluster[sensor][\"all_band\"]\n",
    "    window_cluster_transform = dict_windows_param_cluster[sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_cluster,window_cluster_transform)\n",
    "    sub_fig = ax4.imshow(window_cluster,extent = extent,cmap = ole,vmin = 0,vmax = n-1)\n",
    "    ax4.set_title(sensor + \" cluster sur la bande visible\",fontsize = 20,pad = 20)\n",
    "    fig.colorbar(sub_fig,ax=ax4,fraction=0.046, pad=0.04)\n",
    "    \n",
    "    #hsv\n",
    "    ax5 = fig.add_subplot(gs[1, 7:-1])\n",
    "    window_hsv = dict_windows_param_cluster_hsv[sensor][\"all_band\"]\n",
    "    window_transform_hsv = dict_windows_param_cluster_hsv[sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_hsv,window_transform_hsv)\n",
    "    sub_fig = ax5.imshow(window_hsv,extent = extent,cmap = ole,vmin = 0,vmax = n-1)\n",
    "    ax5.set_title(sensor + \" cluster sur la bande HSV\",fontsize = 20,pad = 20)\n",
    "    fig.colorbar(sub_fig,ax=ax5,fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ## plot du patch visible\n",
    "    ax6 = fig.add_subplot(gs[1, 3:6])\n",
    "    window_vis = dict_windows_param[sensor][\"all_band\"]\n",
    "    window_transform_vis = dict_windows_param[sensor][\"win_transform\"]\n",
    "    show(window_vis,transform = window_transform_vis,ax = ax6)\n",
    "    ax6.set_title(' ',fontsize = 20,pad = 20)\n",
    "    \n",
    "    ## paramètres d'affichage\n",
    "    modification = '_calibree'\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/clustering/visible/\"+ str(sensor)+\".png\"\n",
    "    fig.savefig(fileout,bbox_inches = 'tight' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure Rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "requested_sensor = [\"S1\"]\n",
    "\n",
    "#n = dict_windows_param_cluster_hsv[\"all_band\"].max()\n",
    "\n",
    "n = 7 # nombre de cluster\n",
    "\n",
    "for sensor in dict_sensor :\n",
    "    ##Création des figures\n",
    "    fig = plt.figure(figsize=(30,22))\n",
    "    gs = GridSpec(2, 10, figure=fig)\n",
    "    gs.update(wspace = 0.0, hspace=0.0) # set the spacing between axes.\n",
    "    \n",
    " ## plot des labels de clustering \n",
    "    #visible\n",
    "    ax4 = fig.add_subplot(gs[1, 0:2])\n",
    "    #n = dict_windows_param_cluster[sensor][\"all_band\"].max()\n",
    "    ole=cm.get_cmap('turbo', n)\n",
    "    \n",
    "    window_cluster = dict_windows_param_cluster[sensor][\"all_band\"]\n",
    "    window_cluster_transform = dict_windows_param_cluster[sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_cluster,window_cluster_transform)\n",
    "    sub_fig = ax4.imshow(window_cluster,extent = extent,cmap = ole,vmin = 0,vmax = n-1)\n",
    "    ax4.set_title(sensor + \" cluster sur la bande visible\",fontsize = 20,pad = 20)\n",
    "    fig.colorbar(sub_fig,ax=ax4,fraction=0.046, pad=0.04)\n",
    "    \n",
    "    #hsv\n",
    "    ax5 = fig.add_subplot(gs[1, 7:-1])\n",
    "    window_hsv = dict_windows_param_cluster_hsv[sensor][\"all_band\"]\n",
    "    window_transform_hsv = dict_windows_param_cluster_hsv[sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_hsv,window_transform_hsv)\n",
    "    sub_fig = ax5.imshow(window_hsv,extent = extent,cmap = ole,vmin = 0,vmax = n-1)\n",
    "    ax5.set_title(sensor + \" cluster sur la bande HSV\",fontsize = 20,pad = 20)\n",
    "    fig.colorbar(sub_fig,ax=ax5,fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ## plot du patch visible\n",
    "    ax6 = fig.add_subplot(gs[1, 3:6])\n",
    "    window_vis = dict_windows_param[sensor][\"all_band\"]\n",
    "    window_transform_vis = dict_windows_param[sensor][\"win_transform\"]\n",
    "    show(window_vis,transform = window_transform_vis,ax = ax6)\n",
    "    ax6.set_title(\"Fenêtrage autour de la sonde \"+sensor,fontsize = 20,pad = 20)\n",
    "    \n",
    "    ## paramètres d'affichage\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Modification/Fenêtrage autour des sondes/\"+ str(sensor)+\".png\"\n",
    "    fig.savefig(fileout,bbox_inches = 'tight' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_windows_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "requested_sensor = [\"S1\"]\n",
    "\n",
    "#n = dict_windows_param_cluster_hsv[sensor][\"all_band\"].max()\n",
    "\n",
    "n = 7 # !!!!!!!!!!!!!!!!!!\n",
    "\n",
    "for sensor in requested_sensor :\n",
    "    \n",
    "    # Propriétés graphiques\n",
    "    fig,ax = plt.subplots(1,1,figsize=(7,5))\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 12\n",
    "    BIGGER_SIZE = 15\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    ## plot du patch visible\n",
    "    \n",
    "    window_vis = dict_windows_param[sensor][\"all_band\"]\n",
    "    window_transform_vis = dict_windows_param[sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_IR,window_transform_IR)\n",
    "    show(window_vis,transform = window_transform_vis,ax = ax)\n",
    "    #ax[0].set_title(' ',fontsize = 20,pad = 20)\n",
    "    \n",
    "    ## paramètres d'affichage\n",
    "    modification = '_visible'\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Rapport/Prediction/patch\"+modification+\".png\"\n",
    "    fig.savefig(fileout,bbox_inches = 'tight' )\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1,figsize=(7,5))\n",
    "    \n",
    "    ## plot du patch IR\n",
    "    window_IR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"all_band\"]\n",
    "    window_transform_IR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_IR,window_transform_IR)\n",
    "    sub_fig = ax.imshow(window_IR,extent = extent, cmap = \"plasma\")\n",
    "    ax.set_title('',fontsize = 20,pad = 20)\n",
    "    cbar = fig.colorbar(sub_fig,ax=ax,fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(label = \"Signal IR\",size = 18)\n",
    "    \n",
    "    \n",
    "    ## paramètres d'affichage\n",
    "    modification = '_IR'\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Rapport/Prediction/patch\"+modification+\".png\"\n",
    "    fig.savefig(fileout,bbox_inches = 'tight' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "requested_sensor = [\"S1\"]\n",
    "\n",
    "#n = dict_windows_param_cluster_hsv[sensor][\"all_band\"].max()\n",
    "\n",
    "n = 7 # !!!!!!!!!!!!!!!!!!\n",
    "\n",
    "for sensor in dict_sensor :\n",
    "    \n",
    "    # Propriétés graphiques\n",
    "    fig = plt.figure(figsize=(30,22))\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 12\n",
    "    BIGGER_SIZE = 15\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    ##Création des figures\n",
    "    gs = GridSpec(2, 10, figure=fig)\n",
    "    gs.update(wspace = 0.0, hspace=0.0) # set the spacing between axes.\n",
    "    \n",
    "    \n",
    "    #### boxplot\n",
    "    ax = fig.add_subplot(gs[0, :])\n",
    "    cmap = sns.color_palette(\"turbo\",n)\n",
    "    data = dict_sensor[sensor]\n",
    "    \n",
    "    #ax.set_ylim(0,1)\n",
    "    sns.boxplot(x='IR',y=\"band N\",\n",
    "               data = data,hue = \"clustering_label_hsv\",palette = cmap,ax = ax, hue_order = [0,1,2,3,4,5,6])\n",
    "\n",
    "    sns.set_theme(style=\"ticks\",font_scale = 2)\n",
    "    sns.despine(offset=0, trim=True)\n",
    "    LONGUEUR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"LONGUEUR\"]\n",
    "\n",
    "    ax.set_ylabel(\"Signal IR normalisée\",fontsize = 20)\n",
    "    plt.title(sensor + ' '+str(LONGUEUR)+ 'm patch' + \" normalisée\")\n",
    "        \n",
    "    ## plot des labels de clustering \n",
    "    #visible\n",
    "    ax4 = fig.add_subplot(gs[1, 0:2])\n",
    "    #n = dict_windows_param_cluster[sensor][\"all_band\"].max()\n",
    "    ole=cm.get_cmap('turbo', n)\n",
    "    \n",
    "    window_cluster = dict_windows_param_cluster[sensor][\"all_band\"]\n",
    "    window_cluster_transform = dict_windows_param_cluster[sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_cluster,window_cluster_transform)\n",
    "    sub_fig = ax4.imshow(window_cluster,extent = extent,cmap = ole,vmin = 0,vmax = n-1)\n",
    "    ax4.set_title(sensor + \" cluster sur la bande visible\",fontsize = 20,pad = 20)\n",
    "    fig.colorbar(sub_fig,ax=ax4,fraction=0.046, pad=0.04)\n",
    "    \n",
    "    #hsv\n",
    "    ax5 = fig.add_subplot(gs[1, 7:-1])\n",
    "    window_hsv = dict_windows_param_cluster_hsv[sensor][\"all_band\"]\n",
    "    window_transform_hsv = dict_windows_param_cluster_hsv[sensor][\"win_transform\"]\n",
    "    extent = plotting_extent(window_hsv,window_transform_hsv)\n",
    "    sub_fig = ax5.imshow(window_hsv,extent = extent,cmap = ole,vmin = 0,vmax = n-1)\n",
    "    ax5.set_title(sensor + \" cluster sur la bande HSV\",fontsize = 20,pad = 20)\n",
    "    fig.colorbar(sub_fig,ax=ax5,fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ## plot du patch visible\n",
    "    ax6 = fig.add_subplot(gs[1, 3:6])\n",
    "    window_vis = dict_windows_param[sensor][\"all_band\"]\n",
    "    window_transform_vis = dict_windows_param[sensor][\"win_transform\"]\n",
    "    show(window_vis,transform = window_transform_vis,ax = ax6)\n",
    "    ax6.set_title(' ',fontsize = 20,pad = 20)\n",
    "    \n",
    "    ## paramètres d'affichage\n",
    "    modification = '_calibree'\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/clustering/hsv/\"+ str(sensor)+\".png\"\n",
    "    fig.savefig(fileout,bbox_inches = 'tight' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "requested_sensor = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]\n",
    "#n = dict_windows_param_cluster_hsv[sensor][\"all_band\"].max()\n",
    "n = 6\n",
    "for sensor in requested_sensor :\n",
    "    \n",
    "    # Propriétés graphiques\n",
    "    fig = plt.figure(figsize=(50,25))\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 12\n",
    "    BIGGER_SIZE = 15\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    ##Création des figures\n",
    "    gs = GridSpec(2, 10, figure=fig)\n",
    "    gs.update(wspace = 0.0, hspace=0.0) # set the spacing between axes.\n",
    "    ax = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    ## boxplot\n",
    "    cmap = sns.color_palette(\"turbo\",n+1)\n",
    "    data = dict_sensor[sensor]\n",
    "    #ax.set_ylim(0,1)\n",
    "    sns.boxplot(x='IR',y=\"calibration\",\n",
    "               data = data,hue = \"clustering_label_vis\",palette = cmap,ax = ax, hue_order = [0,1,2,3,4,5,6])\n",
    "\n",
    "    sns.set_theme(style=\"ticks\",font_scale = 2)\n",
    "    sns.despine(offset=0, trim=True)\n",
    "    LONGUEUR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"LONGUEUR\"]\n",
    "\n",
    "    ax.set_ylabel(\"Signal IR, valeurs sans normalisation\",fontsize = 15)\n",
    "    plt.title(sensor + ' '+str(LONGUEUR)+ 'm patch')\n",
    "    \n",
    "    ## paramètres d'affichage\n",
    "    modification = '_calibree'\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/\"+ str(sensor)+modification+\".png\"\n",
    "    #fig.savefig(fileout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"calibration\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "requested_sensor = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]\n",
    "#n = dict_windows_param_cluster_hsv[sensor][\"all_band\"].max()\n",
    "n = 6\n",
    "for sensor in requested_sensor :\n",
    "    \n",
    "    # Propriétés graphiques\n",
    "    fig = plt.figure(figsize=(50,25))\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 12\n",
    "    BIGGER_SIZE = 15\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    ##Création des figures\n",
    "    gs = GridSpec(2, 10, figure=fig)\n",
    "    gs.update(wspace = 0.0, hspace=0.0) # set the spacing between axes.\n",
    "    ax = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    ## boxplot\n",
    "    cmap = sns.color_palette(\"turbo\",n+1)\n",
    "    data = dict_sensor[sensor]\n",
    "    #ax.set_ylim(0,1)\n",
    "    sns.boxplot(x='IR',y=\"calibration\",\n",
    "               data = data,hue = \"clustering_label_vis\",palette = cmap,ax = ax, hue_order = [0,1,2,3,4,5,6])\n",
    "\n",
    "    sns.set_theme(style=\"ticks\",font_scale = 2)\n",
    "    sns.despine(offset=0, trim=True)\n",
    "    LONGUEUR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][sensor][\"LONGUEUR\"]\n",
    "\n",
    "    ax.set_ylabel(\"Signal IR, valeurs sans normalisation\",fontsize = 15)\n",
    "    plt.title(sensor + ' '+str(LONGUEUR)+ 'm patch')\n",
    "    \n",
    "    ## paramètres d'affichage\n",
    "    modification = '_calibree'\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/\"+ str(sensor)+modification+\".png\"\n",
    "    #fig.savefig(fileout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANNEXE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Suppression de l'effet de la plaque et mise à jour de Dict_IR avec np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supress_circle_value (ls_path_tif,dict_IR,r2 = 0.5) :\n",
    "    \"\"\"\n",
    "    Création d'un dictionnaire classé par IR contenant toutes les données comprise entre un rayon r1 et r2, \n",
    "    \"\"\"\n",
    "    \n",
    "    dict_suppress_plaque = {}\n",
    "\n",
    "    for i,IR in enumerate(dict_IR) :\n",
    "        dict_value_sensor = {}\n",
    "        with rio.open(ls_path_tif[i]) as dataset : # ouverture du fichier obligatoire pour recup la valeur\n",
    "            for sensor in dict_IR[IR][\"dict_windows\"] :\n",
    "                if sensor in [\"S10\",\"S3-AIR\"] : # sonde sans plaque\n",
    "                    print(sensor,\"Ne présente pas de plaque\")\n",
    "                    \n",
    "                else:\n",
    "                    #print(sensor)\n",
    "                    res = dict_IR[IR][\"dict_windows_param\"][sensor][\"resolution\"] # resolution [x,y]\n",
    "                    sensor_dataframe = dict_IR[IR][\"dict_windows\"][sensor]\n",
    "                    mid_indice = (dict_IR[IR][\"dict_windows_param\"][sensor]['win'].width) # les indices commencent à 0 !\n",
    "\n",
    "                    mid_x = sensor_dataframe.iloc[len(sensor_dataframe)//2][\"x\"] \n",
    "                    mid_y = sensor_dataframe.iloc[(mid_indice//2)-1][\"y\"]# la valeur du milieu est //2 \n",
    "\n",
    "                    #list des valeurs autour de [0, 2pi] , mouvement anti-horaire\n",
    "                    theta = np.linspace(0,np.pi*2,round(np.pi*2/res[0]))\n",
    "                    ls_x = np.empty([1]) ; ls_y = np.empty([1])\n",
    "\n",
    "                    #recherche de points entre deux rayon r1 et r2\n",
    "                    r1 = 0.0\n",
    "\n",
    "                    for THETA in theta :\n",
    "                        #\n",
    "                        x1 = mid_x + r1*np.cos(THETA)\n",
    "                        y1 = mid_y + r1*np.sin(THETA)\n",
    "\n",
    "                        x2 = mid_x + r2*np.cos(THETA)\n",
    "                        y2 = mid_y + r2*np.sin(THETA)\n",
    "\n",
    "                        ls_x = np.append(ls_x,np.linspace(x1,x2,round((r2-r1)/res[0]))) \n",
    "                        ls_y = np.append(ls_y,np.linspace(y1,y2,round((r2-r1)/res[1])))\n",
    "\n",
    "                    ls_x = np.delete(ls_x,0) ; ls_y = np.delete(ls_y,0)\n",
    "\n",
    "                    dict_IR[IR][\"dict_windows_param\"][sensor]['win'].width # résolution -> nb de pixel == nb d'indice \n",
    "\n",
    "                    ls_value = []\n",
    "                    for k in range(len(ls_x)) :\n",
    "\n",
    "                        for value in dataset.sample([(float(ls_x[k]),float(ls_y[k]))]) : \n",
    "                            ls_value.append(float(value))\n",
    "\n",
    "                    dict_value_sensor[sensor] = pd.DataFrame(np.array([ls_x,ls_y,ls_value],dtype = float).T,columns = \n",
    "                                                             [\"x\",\"y\",\"value\"])\n",
    "            \n",
    "                    dict_suppress_plaque[IR] = dict_value_sensor\n",
    "            \n",
    "                    ##Conversion des pixels proche de la plaque en np.NAN\n",
    "                    DICT_SENSOR = dict_sensor[sensor].loc[dict_sensor[sensor][\"IR\"] == IR] #dictionnaire des sensors\n",
    "                    DICT_SS_PLAQUE = dict_suppress_plaque[IR][sensor] # dictionnaire sans les plaques\n",
    "\n",
    "                    #On pourrait recupérer les résultats de ls_x et ls_y à modifier\n",
    "                    condition  = (DICT_SENSOR[\"y\"]>DICT_SS_PLAQUE[\"y\"].min()) & (DICT_SENSOR[\"y\"]<DICT_SS_PLAQUE[\"y\"].max())\n",
    "                    condition2 = (DICT_SENSOR[\"x\"]>DICT_SS_PLAQUE[\"x\"].min()) & (DICT_SENSOR[\"x\"]<DICT_SS_PLAQUE[\"x\"].max())\n",
    "                    #set to NaN dans le DataFrame\n",
    "                    DICT_SENSOR.loc[condition & condition2,\"origin band\" : \"band N\"] = np.NAN\n",
    "\n",
    "                    #Modification des valeurs directement dans l'array correspondant\n",
    "\n",
    "                    ls_x_row , ls_y_col = [] , [] #listes des valeurs x et y \n",
    "                    dataframe_position = DICT_SENSOR.loc[condition & condition2][[\"x\",\"y\"]].values #conversion df -> list\n",
    "\n",
    "                    print(ls_path_tif[0],sensor) #print de contrôle\n",
    "                    for x_val,y_val in dataframe_position :\n",
    "                        x_row,y_col = dataset.index(x_val,y_val) # valueur d'indice de chaque position\n",
    "                        win_propiety = dict_IR[IR][\"dict_windows_param\"][sensor][\"win\"]\n",
    "                        #conversion des indices de l'IR -> indice dans la fenêtre\n",
    "                        x_row = np.absolute(win_propiety.row_off-x_row) \n",
    "                        y_col = np.absolute(win_propiety.col_off-y_col)\n",
    "\n",
    "                        #set to NaN dans l'array\n",
    "                        dict_IR[IR][\"dict_windows_param\"][sensor][\"all_band\"][x_row,y_col] = np.NAN\n",
    "\n",
    "    print(dict_IR[\"IR_6H55\"][\"dict_windows_param\"][\"S2\"][\"all_band\"][x_row-1: x_row+12,y_col-5 : y_col])\n",
    "        \n",
    "    return dict_suppress_plaque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_suppress_plaque = supress_circle_value (ls_path_tif,dict_IR,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise à jour de dict_sensor et dict_IR avec les données de calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration des IR à l'aide des valeurs de RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_to_DataFrame(dict_sensor,dict_IR,dict_rms):\n",
    "    \"\"\"\n",
    "    Mise à jour de deux dictionnaires avec les valeurs de calibration\n",
    "    \"\"\"\n",
    "\n",
    "    for sensor in dict_sensor :\n",
    "        for k,IR in enumerate(dict_IR) :\n",
    "            \n",
    "            # calibration sous forme d'array pour affichage imshow()\n",
    "            calibration = dict_rms[sensor]['RMS'][k]\n",
    "            IR_calibration = dict_IR[IR][\"dict_windows_param\"][sensor][\"all_band\"] + calibration\n",
    "            \n",
    "            dict_IR[IR][\"dict_windows_param\"][sensor][\"calibration\"] = IR_calibration\n",
    "            dict_IR[IR][\"dict_windows_param\"][sensor][\"calibration_value\"] = calibration\n",
    "            # usage d'un mask pour repérer les valeurs de chaque IR \n",
    "            mask = dict_sensor[sensor][\"IR\"].str.startswith(str(IR))\n",
    "            \n",
    "            # valeur unique de calibration par sensor par IR, situé dans le dict dict_IR qui contient toutes \n",
    "            # les données brute/dataframe classées par IR \n",
    "            cal = dict_IR[IR][\"dict_windows_param\"][sensor][\"calibration_value\"]\n",
    "            \n",
    "            print(sensor,IR,'Calibration value :',str(cal)[0:7])\n",
    "            \n",
    "            #Assigniation des donnees au dataframe \n",
    "            dict_sensor[sensor].loc[mask,\"calibration\"] = dict_sensor[sensor]['origin band'].add(cal)\n",
    "            \n",
    "\n",
    "        print(\"completed :\",sensor)\n",
    "    print(\"Les valeurs sous forme d'array sont dispo ici -> dict_IR[IR]['dict_windows_param'][sensor]['calibration']\")\n",
    "    print(\"La valeur de calibration est dispo ici -> dict_IR[IR]['dict_windows_param'][sensor]['calibration_value']\")\n",
    "    return dict_sensor,dict_IR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sensor,dict_IR = calibration_to_DataFrame(dict_sensor,dict_IR,dict_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_sensor[sensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération de l'IR 7h15 pour toutes les sondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_calibration_to_DataFrame(dict_sensor,dict_IR,dict_sensor_calibration):\n",
    "    \"\"\"\n",
    "    Création d'un DataFrame par sonde contenant les positions et les des bandes normalisées, réunit sous \n",
    "    un dictionnaire\n",
    "    \"\"\"\n",
    "\n",
    "    for sensor in dict_sensor :\n",
    "        for k,IR in enumerate(dict_IR) :\n",
    "            # calibration sous forme matricielle pour affichage imshow()\n",
    "            calibration = dict_rms[sensor]['RMS'][k]\n",
    "            IR_calibration = dict_IR[IR][\"dict_windows_param\"][sensor][\"all_band\"] + calibration\n",
    "            #dict_calibration_IR[IR] = IR_calibration\n",
    "            dict_IR[IR][\"dict_windows_param\"][sensor][\"calibration\"] = IR_calibration\n",
    "            dict_IR[IR][\"dict_windows_param\"][sensor][\"calibration_value\"] = calibration\n",
    "            # usage d'un mask pour repérer les valeurs de chaque IR \n",
    "            mask = dict_sensor[sensor][\"IR\"].str.startswith(str(IR))\n",
    "            \n",
    "            # valeur unique de calibration par sensor par IR, situé dans le dict dict_IR qui contient toutes \n",
    "            # les données brute/dataframe classées par IR \n",
    "            cal = dict_IR[IR][\"dict_windows_param\"][sensor][\"calibration_value\"]\n",
    "            \n",
    "            print(sensor,IR,'Calibration value :',str(cal)[0:7])\n",
    "            \n",
    "            #Assigniation des donnees au dataframe \n",
    "            dict_sensor[sensor].loc[mask,\"calibration\"] = dict_sensor[sensor]['origin band'].add(cal)\n",
    "            \n",
    "\n",
    "        print(\"completed :\",sensor)\n",
    "    return dict_sensor,dict_IR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_IR_calibration = {}\n",
    "IR_calibration = {}\n",
    "IR_calibration_value = {}\n",
    "IR_calibration_2 = {}\n",
    "IR_calibration_value_2 = {}\n",
    "for sensor in dict_sensor_calibration :\n",
    "    IR = \"IR_6H55\"\n",
    "    interpoled_calibration = (dict_sensor_calibration[sensor][\"Interpolate_time\"][1],\n",
    "                              dict_sensor_calibration[sensor][\"Interpolate_value\"][1])\n",
    "    print(interpoled_calibration)\n",
    "\n",
    "    IR_calibration[sensor] = dict_IR[IR][\"dict_windows_param\"][sensor][\"all_band\"] + interpoled_calibration[1]\n",
    "    IR_calibration_value[sensor] = interpoled_calibration[1]\n",
    "    IR_name = 'IR_'+str(interpoled_calibration[0].hour)+'H'+str(interpoled_calibration[0].minute)\n",
    "    \n",
    "    \n",
    "    IR_2 = \"IR_7H29\"\n",
    "    IR_calibration_2[sensor] = dict_IR[IR_2][\"dict_windows_param\"][sensor][\"all_band\"] - interpoled_calibration[1]\n",
    "    IR_calibration_value_2[sensor] = interpoled_calibration[1]\n",
    "    IR_name_2 = 'IR_'+str(interpoled_calibration[0].hour)+'H'+str(interpoled_calibration[0].minute)+\"_2\"\n",
    "    \n",
    "    \n",
    "\n",
    "dict_IR_calibration[IR_name] = {\"calibration_array\" : IR_calibration, \n",
    "                                   \"Interpolate_value\" : IR_calibration_value }\n",
    "\n",
    "dict_IR_calibration[IR_name_2] = {\"calibration_array\" : IR_calibration_2, \n",
    "                                   \"Interpolate_value\" : IR_calibration_value_2 }\n",
    "dict_IR_calibration.keys()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_suppress_plaque = {}\n",
    "requested_IR = [\"IR_6H55\"]\n",
    "requested_sensor = [\"S2\"]\n",
    "r2 = 0.3\n",
    "\n",
    "for i,IR in enumerate(requested_IR) :\n",
    "    dict_value_sensor = {}\n",
    "    with rio.open(ls_path_tif[i]) as dataset : # ouverture du fichier obligatoire pour recup la valeur\n",
    "        for sensor in requested_sensor :\n",
    "            if sensor in [\"S10\",\"S3-AIR\"] : # sonde sans plaque\n",
    "                print(sensor,\"Ne présente pas de plaque\")\n",
    "\n",
    "            else :\n",
    "                #print(sensor)\n",
    "                res = dict_IR[IR][\"dict_windows_param\"][sensor][\"resolution\"] # resolution [x,y]\n",
    "                sensor_dataframe = dict_IR[IR][\"dict_windows\"][sensor]\n",
    "                mid_indice = (dict_IR[IR][\"dict_windows_param\"][sensor]['win'].width) # les indices commencent à 0 !\n",
    "\n",
    "                mid_x = sensor_dataframe.iloc[len(sensor_dataframe)//2][\"x\"] \n",
    "                mid_y = sensor_dataframe.iloc[(mid_indice//2)-1][\"y\"]# la valeur du milieu est //2 \n",
    "\n",
    "                #list des valeurs autour de [0, 2pi] , mouvement anti-horaire\n",
    "                theta = np.linspace(0,np.pi*2,round(np.pi*2/res[0]))\n",
    "                ls_x = np.empty([1]) ; ls_y = np.empty([1])\n",
    "\n",
    "                #recherche de points entre deux rayon r1 et r2\n",
    "                r1 = 0.0\n",
    "\n",
    "                for THETA in theta :\n",
    "                    #\n",
    "                    x1 = mid_x + r1*np.cos(THETA)\n",
    "                    y1 = mid_y + r1*np.sin(THETA)\n",
    "\n",
    "                    x2 = mid_x + r2*np.cos(THETA)\n",
    "                    y2 = mid_y + r2*np.sin(THETA)\n",
    "\n",
    "                    ls_x = np.append(ls_x,np.linspace(x1,x2,round((r2-r1)/res[0]))) \n",
    "                    ls_y = np.append(ls_y,np.linspace(y1,y2,round((r2-r1)/res[1])))\n",
    "\n",
    "                ls_x = np.delete(ls_x,0) ; ls_y = np.delete(ls_y,0)\n",
    "\n",
    "                dict_IR[IR][\"dict_windows_param\"][sensor]['win'].width # résolution -> nb de pixel == nb d'indice \n",
    "                ls_value = []\n",
    "                for k in range(len(ls_x)) :\n",
    "\n",
    "                    for value in dataset.sample([(float(ls_x[k]),float(ls_y[k]))]) : \n",
    "                        ls_value.append(float(value))\n",
    "\n",
    "                dict_value_sensor[sensor] = pd.DataFrame(np.array([ls_x,ls_y,ls_value],dtype = float).T,columns = \n",
    "                                                         [\"x\",\"y\",\"value\"])\n",
    "                dict_suppress_plaque[IR] = dict_value_sensor\n",
    "                \n",
    "                ## Conversion des pixels proche de la plaque en np.NAN\n",
    "                DICT_SENSOR = dict_sensor[sensor].loc[dict_sensor[sensor][\"IR\"] == IR]\n",
    "                DICT_SS_PLAQUE = dict_suppress_plaque[IR][sensor]\n",
    "                \n",
    "                #On pourrait recupérer les résultats de ls_x et ls_y à modifier\n",
    "                condition  = (DICT_SENSOR[\"y\"]>DICT_SS_PLAQUE[\"y\"].min()) & (DICT_SENSOR[\"y\"]<DICT_SS_PLAQUE[\"y\"].max())\n",
    "                condition2 = (DICT_SENSOR[\"x\"]>DICT_SS_PLAQUE[\"x\"].min()) & (DICT_SENSOR[\"x\"]<DICT_SS_PLAQUE[\"x\"].max())\n",
    "                #set to NaN dans le DataFrame\n",
    "                DICT_SENSOR.loc[condition & condition2,\"origin band\" : \"band N\"] = np.NAN\n",
    "                \n",
    "                #Modification des valeurs directement dans l'array correspondant\n",
    "                \n",
    "                ls_x_row , ls_y_col = [] , [] #listes des valeurs x et y \n",
    "                dataframe_position = DICT_SENSOR.loc[condition & condition2][[\"x\",\"y\"]].values #conversion df -> list\n",
    "                \n",
    "                print(ls_path_tif[0],sensor) #print de contrôle\n",
    "                for x_val,y_val in dataframe_position :\n",
    "                    x_row,y_col = dataset.index(x_val,y_val) # valueur d'indice de chaque position\n",
    "                    win_propiety = dict_IR[IR][\"dict_windows_param\"][sensor][\"win\"]\n",
    "                    #conversion des indices de l'IR -> indice dans la fenêtre\n",
    "                    x_row = np.absolute(win_propiety.row_off-x_row) \n",
    "                    y_col = np.absolute(win_propiety.col_off-y_col)\n",
    "                    \n",
    "                    #set to NaN dans l'array\n",
    "                    dict_IR[IR][\"dict_windows_param\"][sensor][\"all_band\"][x_row,y_col] = np.NAN\n",
    "\n",
    "dict_IR[\"IR_6H55\"][\"dict_windows_param\"][\"S2\"][\"all_band\"][x_row-1: x_row+12,y_col-5 : y_col]\n",
    "                \n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_temp_complete = SLICE['T4'].values # contient les valeurs de S10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert training data to right shape\n",
    "trai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = SLICE.loc[SLICE[\"Time\"] < \"2019-04-14 15:00:00\"]['T4'].values.reshape(-1,1) # X\n",
    "test = SLICE.loc[SLICE[\"Time\"] >= \"2019-04-14 15:00:00\"]['T4'].values.reshape(-1,1) # Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "train_scaled = sc.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create supervized data with 2 hours input and 1 output \n",
    "hours = 2 # hours \n",
    "n = hours * 4\n",
    "X_train = train[:-n]\n",
    "X_test = train[-n:]\n",
    "Y_train = train[:-n]\n",
    "Y_test = train[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nsepy import get_history\n",
    "from datetime import datetime\n",
    "\n",
    "startDate = datetime(2019,1,1)\n",
    "endDate   = datetime(2020,10,5)\n",
    "\n",
    "#Fetching the Data\n",
    "StockData = get_history(symbol = \"INFY\" , start = startDate , end = endDate)\n",
    "print(StockData.shape)\n",
    "StockData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column as date\n",
    "StockData['TradeDate']=StockData.index\n",
    "\n",
    "# Plotting the sotck prices\n",
    "StockData.plot(x='TradeDate', y='Close', kind='line', figsize=(20,6), rot=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the closing prices of each day\n",
    "FullData = StockData[['Close']].values\n",
    "print(FullData[0:5])\n",
    "\n",
    "# Feature Scaling for fast training of neural networks\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    " \n",
    "# Choosing between Standardization or normalization\n",
    "#sc = StandardScaler()\n",
    "sc=MinMaxScaler()\n",
    " \n",
    "DataScaler = sc.fit(FullData)\n",
    "X=DataScaler.transform(FullData)\n",
    "#X=FullData\n",
    " \n",
    "print('### After Normalization ###')\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into samples\n",
    "X_samples = []\n",
    "y_samples = []\n",
    "NumerofRows = len(X)\n",
    "TimeSteps = 10 # nxt day's Price Prediction is based on last how many day's prices\n",
    "# On commence au 10e jour \n",
    "\n",
    "# Iterate thru the values to create combinations\n",
    "for i in range(TimeSteps,NumerofRows,1) : # On prend tjrs 10 jours\n",
    "    # ex i = 10 -> [0 1 2 3 4 5 6 7 8 9]\n",
    "    # ex i = 11 -> [ 1  2  3  4  5  6  7  8  9 10]\n",
    "    x_sample = X[i-TimeSteps:i]\n",
    "    y_sample = X[i]\n",
    "    X_samples.append(x_sample)\n",
    "    y_samples.append(y_sample)\n",
    "len(x_sample)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(TimeSteps,NumerofRows,1) :\n",
    "    \n",
    "    print(i,np.arange(i-TimeSteps,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the Input as a 3D (number of samples, Time Steps, Features)\n",
    "X_data=np.array(X_samples)\n",
    "X_data=X_data.reshape(X_data.shape[0],X_data.shape[1], 1)\n",
    "print('\\n#### Input Data shape ####')\n",
    "print(X_data.shape)\n",
    " \n",
    "# We do not reshape y as a 3D data  as it is supposed to be a single column only\n",
    "y_data=np.array(y_samples)\n",
    "y_data=y_data.reshape(y_data.shape[0], 1)\n",
    "print('\\n#### Output Data shape ####')\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=np.array(X_samples)\n",
    "X_data=X_data.reshape(X_data.shape[0],X_data.shape[1], 1)\n",
    "print('\\n#### Input Data shape ####')\n",
    "print(X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test = \"C:/Users/Alexandre/Desktop/Cours/Stage/airline-passengers.csv\"\n",
    "dataframe = pd.read_csv(file_test,usecols = [1],engine = 'python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "#normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "dataset = scaler.fit_transform(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test sets\n",
    "train_size = int(len(dataset)*0.67) #96\n",
    "test_size  = len(dataset) - train_size # 48\n",
    "train, test = dataset[0:train_size,:] , dataset[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples,time steps, features]\n",
    "trainX = np.reshape(trainX,(trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(unit = 10, input_shape =(1,look_back) ) )\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.fit(trainX, trainY, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.array(train[0:-2]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX[-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX[-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clustering_label\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette(\"turbo\",as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette('turbo',7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.color_palette(\"husl\") as cmap :\n",
    "        data = dict_sensor[sensor]\n",
    "        \n",
    "        ax = fig.add_subplot(gs[0, :])\n",
    "        \n",
    "        ax.set_ylim(0,1)\n",
    "        sns.boxplot(x='IR',y=\"band N\",\n",
    "                   data = data,palette = cmap,ax = ax )\n",
    "        sns.set_theme(style=\"ticks\",font_scale = 2)\n",
    "        sns.despine(offset=10, trim=True)\n",
    "        LONGUEUR = dict_IR[\"IR_6H55\"][\"dict_windows_param\"][\"S10\"][\"LONGUEUR\"]\n",
    "        \n",
    "        ax.set_ylabel(\"Normalisation commune\",fontsize = 20)\n",
    "        plt.title(sensor + ' '+str(LONGUEUR)+ 'm patch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_calibration_sensor = {}\n",
    "for sensor in dict_sensor :\n",
    "    dict_calibration_IR = {}\n",
    "    for k,IR in enumerate(dict_IR) :\n",
    "        calibration = dict_rms[sensor]['RMS'][k]\n",
    "        print(sensor,IR,\"valeur de calibration :\",calibration)\n",
    "        IR_calibration = dict_IR[IR][\"dict_windows_param\"][sensor][\"all_band\"] + calibration\n",
    "        dict_calibration_IR[IR] = IR_calibration\n",
    "        dict_IR[IR][\"dict_windows_param\"][sensor][\"calibration\"] = dict_calibration_IR\n",
    "        dict_IR[IR][\"dict_windows_param\"][sensor][\"calibration_value\"] = calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_IR[\"IR_17H27\"][\"dict_windows_param\"][\"S9\"][\"calibration_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_IR[IR][\"dict_windows\"][sensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_temp_IR[\"IR_6H55\"]['time'] = pd.Timestamp('2019-04-14 07:00:00')\n",
    "pseudo_temp_IR[\"IR_7H29\"]['time'] = pd.Timestamp('2019-04-14 07:30:00')\n",
    "pseudo_temp_IR[\"IR_8H22\"]['time'] = pd.Timestamp('2019-04-14 08:30:00')\n",
    "pseudo_temp_IR[\"IR_9H28\"]['time'] = pd.Timestamp('2019-04-14 09:30:00')\n",
    "pseudo_temp_IR[\"IR_10H22\"]['time'] = pd.Timestamp('2019-04-14 10:30:00')\n",
    "pseudo_temp_IR[\"IR_11H27\"]['time'] = pd.Timestamp('2019-04-14 11:30:00')\n",
    "pseudo_temp_IR[\"IR_12H31\"]['time'] = pd.Timestamp('2019-04-14 12:30:00')\n",
    "pseudo_temp_IR[\"IR_13H26\"]['time'] = pd.Timestamp('2019-04-14 13:30:00')\n",
    "pseudo_temp_IR[\"IR_15H59\"]['time'] = pd.Timestamp('2019-04-14 16:00:00')\n",
    "pseudo_temp_IR[\"IR_17H27\"]['time'] = pd.Timestamp('2019-04-14 17:30:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moyenne 4 pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetif = ['6H55','7H29','8H22','9H28','10H22','11H27','12H31','13H26',\n",
    "                               '15H59','17H27']\n",
    "ls_path_tif,filetif = get_tif(filetif)\n",
    "\n",
    "dict_value_IR = {}\n",
    "\n",
    "for i,IR in enumerate(dict_IR) :\n",
    "    dict_value_target = {}\n",
    "    with rio.open(ls_path_tif[i]) as dataset : # ouverture du fichier obligatoire pour recup la valeur\n",
    "        for target in dict_IR[IR][\"dict_windows\"] :\n",
    "\n",
    "            hop = dict_IR[IR][\"dict_windows\"][target]\n",
    "            mid_indice = (dict_IR[IR][\"dict_windows_param\"][target]['win'].width) # les indices commencent à 0 !\n",
    "\n",
    "            mid_x = hop.iloc[len(hop)//2][\"x\"] \n",
    "            mid_y = hop.iloc[(mid_indice//2)-1][\"y\"]# la valeur du milieu est //2 \n",
    "\n",
    "            #list des valeurs autour de [0, 2pi] , mouvement anti-horaire\n",
    "\n",
    "            theta = [0,np.pi/2,np.pi,np.pi * (3/2)]\n",
    "            r = 1\n",
    "            \n",
    "\n",
    "            # allocation des matrices \n",
    "            ls_x = [] ; ls_y = []\n",
    "            print(target)\n",
    "            print(\"mid_x :\",mid_x,\"mid_y :\",mid_y)\n",
    "\n",
    "            for THETA in theta :\n",
    "                x = mid_x + r*np.cos(THETA)\n",
    "                y = mid_y + r*np.sin(THETA)\n",
    "                print(\"x :\",x,\"y :\",y)\n",
    "                ls_x.append(x) ; ls_y.append(y)\n",
    "\n",
    "\n",
    "            with rio.open(ls_path_tif[i]) as dataset : # ouverture du fichier obligatoire pour recup la valeur\n",
    "                print(ls_path_tif[i])\n",
    "\n",
    "                dict_IR[IR][\"dict_windows_param\"][target]['win'].width # résolution -> nb de pixel == nb d'indice \n",
    "\n",
    "                ls_value = []\n",
    "                for k in range(len(ls_x)) :\n",
    "\n",
    "                    for value in dataset.sample([(float(ls_x[k]),float(ls_y[k]))]) : \n",
    "                        ls_value.append(float(value))\n",
    "\n",
    "                dict_value_target[target] = pd.DataFrame(np.array([ls_x,ls_y,ls_value],dtype = float).T,columns = \n",
    "                                                         [\"x\",\"y\",\"value\"])\n",
    "    dict_value_IR[IR] = dict_value_target\n",
    "                \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_path_tif,filetif = get_tif(filetif)\n",
    "\n",
    "dict_value_IR = {}\n",
    "\n",
    "for i,IR in enumerate(dict_IR) :\n",
    "    dict_value_target = {}\n",
    "    with rio.open(ls_path_tif[i]) as dataset : # ouverture du fichier obligatoire pour recup la valeur\n",
    "        for target in dict_IR[IR][\"dict_windows\"] :\n",
    "            \n",
    "            res = dict_IR[IR][\"dict_windows_param\"][target][\"resolution\"] # resolution [x,y]\n",
    "            hop = dict_IR[IR][\"dict_windows\"][target]\n",
    "            mid_indice = (dict_IR[IR][\"dict_windows_param\"][target]['win'].width) # les indices commencent à 0 !\n",
    "\n",
    "            mid_x = hop.iloc[len(hop)//2][\"x\"] \n",
    "            mid_y = hop.iloc[(mid_indice//2)-1][\"y\"]# la valeur du milieu est //2 \n",
    "\n",
    "            #list des valeurs autour de [0, 2pi] , mouvement anti-horaire\n",
    "            theta = np.linspace(0,np.pi*2,round(np.pi*2/res[0]))\n",
    "            ls_x = np.empty([1]) ; ls_y = np.empty([1])\n",
    "            \n",
    "            #recherche de points entre deux rayon r1 et r2\n",
    "            r1 = 0.7 ; r2 = 1.5\n",
    "            for THETA in theta :\n",
    "                #\n",
    "                x1 = mid_x + r1*np.cos(THETA)\n",
    "                y1 = mid_y + r1*np.sin(THETA)\n",
    "                \n",
    "                x2 = mid_x + r2*np.cos(THETA)\n",
    "                y2 = mid_y + r2*np.sin(THETA)\n",
    "\n",
    "                ls_x = np.append(ls_x,np.linspace(x1,x2,round((r2-r1)/res[0]))) \n",
    "                ls_y = np.append(ls_y,np.linspace(y1,y2,round((r2-r1)/res[1])))\n",
    "\n",
    "            ls_x = np.delete(ls_x,0) ; ls_y = np.delete(ls_y,0)\n",
    "\n",
    "\n",
    "            with rio.open(ls_path_tif[i]) as dataset : # ouverture du fichier obligatoire pour recup la valeur\n",
    "                \n",
    "\n",
    "                dict_IR[IR][\"dict_windows_param\"][target]['win'].width # résolution -> nb de pixel == nb d'indice \n",
    "\n",
    "                ls_value = []\n",
    "                for k in range(len(ls_x)) :\n",
    "\n",
    "                    for value in dataset.sample([(float(ls_x[k]),float(ls_y[k]))]) : \n",
    "                        ls_value.append(float(value))\n",
    "\n",
    "                dict_value_target[target] = pd.DataFrame(np.array([ls_x,ls_y,ls_value],dtype = float).T,columns = \n",
    "                                                         [\"x\",\"y\",\"value\"])\n",
    "    print(IR)\n",
    "    dict_value_IR[IR] = dict_value_target\n",
    "    print(\"nombre de coordonnées utilisée pour la moyenne :\",dict_value_IR[IR][target].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "S1 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"])\n",
    "S2 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"])\n",
    "S3_AIR = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"])\n",
    "S4 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"])\n",
    "S5 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"])\n",
    "S6 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"])\n",
    "S7 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"])\n",
    "S8 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"])\n",
    "S9 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"])\n",
    "S10 = pd.DataFrame(columns = [\"x\",\"y\",\"origin band\",\"band 1\",\"band N\",\"IR\"])\n",
    "dict_sensor = {\"S1\" : S1,\"S2\" : S2,\"S3-AIR\" : S3_AIR,\"S4\" : S4,\"S5\" : S5,\n",
    "            \"S6\" : S6,\"S7\" : S7,\"S8\" : S8,\"S9\" : S9,\"S10\" : S10}\n",
    "\n",
    "BAND_MIN_N = 0\n",
    "BAND_MAX_N = 0\n",
    "for sensor in dict_sensor :\n",
    "\n",
    "    for target in dict_IR :\n",
    "        min_= dict_IR[target][\"dict_windows\"][sensor][\"band 1\"].min()\n",
    "        max_= dict_IR[target][\"dict_windows\"][sensor][\"band 1\"].max()\n",
    "        if min_ < BAND_MIN_N :\n",
    "            BAND_MIN_N = min_\n",
    "            \n",
    "            \n",
    "        if max_ > BAND_MAX_N :\n",
    "            BAND_MAX_N = max_\n",
    "            \n",
    "\n",
    "print(\"BAND_MIN_N\",BAND_MIN_N) # valeur minimale retenue pour la normalisation\n",
    "print(\"BAND_MAX_N\",BAND_MAX_N) # valeur maximale retenue pour la normalisation\n",
    "\n",
    "for sensor in dict_sensor :\n",
    "    k = 0 \n",
    "    \n",
    "    for target in dict_IR :\n",
    "\n",
    "        band_shape = dict_IR[target][\"dict_windows\"][sensor][[\"band 1\"]].shape[0]\n",
    "\n",
    "        band_min = dict_IR[target][\"dict_windows\"][sensor][\"band 1\"].min()\n",
    "        band_max = dict_IR[target][\"dict_windows\"][sensor][\"band 1\"].max()\n",
    "        \n",
    "        x = pd.DataFrame(dict_IR[target][\"dict_windows\"][sensor][\"x\"])\n",
    "        y = pd.DataFrame(dict_IR[target][\"dict_windows\"][sensor][\"y\"])\n",
    "        # band originale, sans normalisation\n",
    "        origin_band = pd.DataFrame(dict_IR[target][\"dict_windows\"][sensor][\"band 1\"])\n",
    "        origin_band.columns = [\"origin band\"]\n",
    "        \n",
    "        # band avec normalisation différente pour chaque IR\n",
    "        band     = pd.DataFrame((dict_IR[target][\"dict_windows\"][sensor][[\"band 1\"]]-band_min)/(band_max-band_min))\n",
    "        \n",
    "        # band avec normalisation commune pour chaque IR\n",
    "        band_N   = pd.DataFrame((dict_IR[target][\"dict_windows\"][sensor][[\"band 1\"]]-BAND_MIN_N)/(BAND_MAX_N-BAND_MIN_N)) \n",
    "        band_N.columns = ['band N']\n",
    "\n",
    "        # Concaténation de plusieurs bandes\n",
    "        cnte = pd.concat([x,y,origin_band,band,band_N],axis=1)\n",
    "        dict_sensor[sensor]=dict_sensor[sensor].append(cnte,ignore_index=True)\n",
    "        \n",
    "        # Repetition du nom de IR pour chaque valeurs -> boxplot\n",
    "        dict_sensor[sensor][\"IR\"][k:(k+band_shape)]  = target\n",
    "        \n",
    "        k+=band_shape\n",
    "    print(\"completed :\",sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_value_IR[IR][sensor].iloc[0][\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_value_IR[IR][sensor][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_value_IR['IR_6H55'][\"S1\"][\"x\"].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X-c_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TARGET = sensor_coord.loc[sensor_coord[\"SensorName\"]==sensor]\n",
    "c_1 = dict_value_IR['IR_6H55'][\"S1\"][\"x\"].iloc[0]\n",
    "c_2 = dict_value_IR['IR_6H55'][\"S1\"][\"x\"].iloc[-1]\n",
    "X = np.array(TARGET[\"x\"],dtype = float)\n",
    "Y = np.array(TARGET[\"y\"],dtype=float)\n",
    "print(X,Y)\n",
    "circle1 = plt.Circle((X,Y),(c_1-X),color='b', fill=False)\n",
    "circle2 = plt.Circle((X,Y),(c_2-X),color='r', fill=False)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim((X-3,X+3 ))\n",
    "ax.set_ylim((Y-3,Y+3 ))\n",
    "ax.add_patch(circle1)\n",
    "ax.add_patch(circle2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot des points choisi pour la pseudo-temp\n",
    "for k in range( len(dict_value_IR[IR][sensor][\"value\"])) :\n",
    "    plt.plot(dict_value_IR[IR][sensor][\"x\"][k],dict_value_IR[IR][sensor][\"y\"][k],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dict_IR['IR_17H27'][\"dict_windows_param\"][\"S3-AIR\"][\"resolution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 1 ; r2 = 2\n",
    "ls_x1 = [] ; ls_y1 = []\n",
    "ls_x2 = [] ; ls_y2 = []\n",
    "for THETA in theta :\n",
    "    x1 = mid_x + r1*np.cos(THETA)\n",
    "    y1 = mid_y + r1*np.sin(THETA)\n",
    "    ls_x1.append(x1) ; ls_y1.append(y1)\n",
    "    x2 = mid_x + r2*np.cos(THETA)\n",
    "    y2 = mid_y + r2*np.sin(THETA)\n",
    "    ls_x2.append(x2) ; ls_y2.append(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 1 ; r2 = 2\n",
    "liste_x = np.empty([1]) ; liste_y = np.empty([1])\n",
    "for THETA in theta :\n",
    "    x1 = mid_x + r1*np.cos(THETA)\n",
    "    y1 = mid_y + r1*np.sin(THETA)\n",
    "    x2 = mid_x + r2*np.cos(THETA)\n",
    "    y2 = mid_y + r2*np.sin(THETA)\n",
    "    \n",
    "    liste_x = np.append(liste_x,np.linspace(x1,x2,round((r2-r1)/res[0]))) \n",
    "    liste_y = np.append(liste_y,np.linspace(y1,y2,round((r2-r1)/res[1])))\n",
    "\n",
    "liste_x = np.delete(liste_x,0) ; liste_y = np.delete(liste_y,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot d'une sonde + Pseudo Temp° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.dates as mdates\n",
    "requested_sensor = [\"S10\"]\n",
    "\n",
    "fig = plt.figure(figsize=(25,15))\n",
    "\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 15\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "gs = GridSpec(2, 10, figure=fig)\n",
    "gs.update(wspace = 0.5, hspace=0.0) # set the spacing between axes.\n",
    "ax = fig.add_subplot(gs[0, :])\n",
    "\n",
    "for sensor in requested_sensor :\n",
    "    \n",
    "    ls_values = [] # listes des valeurs\n",
    "    ls_time   = [] # listes des temps \n",
    "    ls_var    = [] # listes des écarts-types\n",
    "    \n",
    "    print(sensor)\n",
    "    for IR in dict_value_IR :\n",
    "        ls_values.append(pseudo_temp[sensor][IR][\"values\"])\n",
    "        ls_time.append(pseudo_temp[sensor][IR][\"time\"])\n",
    "        ls_var.append(pseudo_temp[sensor][IR][\"var\"])\n",
    "        \n",
    "    # [ val - sigma , val + sigma]\n",
    "    ls_sigma = [np.array(ls_values)-np.array(ls_var),np.array(ls_values)+np.array(ls_var)]\n",
    "    SLICE = dict_temp_sensor[sensor]\n",
    "   \n",
    "    # Plot de la température des sondes\n",
    "    plottingtemp_single_label_IR_a(SLICE,fig,ax,'T4',200,6)\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax3 = ax.twinx() # instantiate a second axes that shares the same x-axis\n",
    "    color = \"tab:red\"\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "\n",
    "    \n",
    "    # Plot de la pseudo Température \n",
    "    ax3.plot(ls_time,ls_values,color = color)\n",
    "    ax3.plot(ls_time,ls_values,'ro',color = color)\n",
    "    ax3.tick_params(axis = 'y', labelcolor = color)\n",
    "    ax3.set_ylabel(\"Pseudo Température\", color = color, fontsize = 20)\n",
    "    ax3.set_ylim(-5,30)\n",
    "    \n",
    "    for w in range(len(ls_time)) :\n",
    "        ax3.text(ls_time[w],ls_values[w]+0.5,str(ls_var[w])[0:5],fontsize = 15) # valeurs d'écart type\n",
    "       \n",
    "    \n",
    "    # Interval de confiance +/- sigma \n",
    "    ax3.plot(ls_time,ls_sigma[0],'m',label = '- sigma') # value - sigma\n",
    "    ax3.plot(ls_time,ls_sigma[1],'m',label = '+ sigma') # value + sigma\n",
    "    ax3.legend(loc='upper right', bbox_to_anchor=(1, 0.9))\n",
    "\n",
    "\n",
    "    # plot des patchs IRs\n",
    "    for k,IR in enumerate(dict_IR) :\n",
    "        ax2 = fig.add_subplot(gs[1, k])\n",
    "        \n",
    "        window_IR = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"all_band\"]\n",
    "        window_transform_IR = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"win_transform\"]\n",
    "        extent = plotting_extent(window_IR,window_transform_IR)\n",
    "        \n",
    "        sub_fig = ax2.imshow(window_IR,extent = extent,cmap ='viridis')\n",
    "        ax2.set_title(IR,fontsize = 20,pad = 20)\n",
    "        fig.colorbar(sub_fig,ax=ax2,fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Plot des targets\n",
    "        TARGET = sensor_coord.loc[sensor_coord[\"SensorName\"]==sensor]\n",
    "        X = np.array(TARGET[\"x\"],dtype = float)\n",
    "        Y = np.array(TARGET[\"y\"],dtype=float)\n",
    "        ax2.plot(X,Y,'r*')\n",
    "        \n",
    "        # Plot des points choisi pour la pseudo-temp\n",
    "        for k in range( len(dict_value_IR[IR][sensor][\"value\"])) :\n",
    "            ax2.plot(dict_value_IR[IR][sensor][\"x\"][k],dict_value_IR[IR][sensor][\"y\"][k],'ro')\n",
    "\n",
    "plt.title(sensor,fontsize = 20)\n",
    "ax.set_xticklabels([str(time.hour)+':'+str(time.minute) for time in SLICE['Time']][::8])\n",
    "ax.set_xlabel('Time' + ' 2019-04-19' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_sensor[sensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot + Fenêtre clustering sur données \"calibrées\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sensor[sensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout d'un polynome de degrée n = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "requested_sensor = [\"S10\"]\n",
    "\n",
    "fig = plt.figure(figsize=(25,15))\n",
    "\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 15\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "gs = GridSpec(2, 10, figure=fig)\n",
    "gs.update(wspace = 0.5, hspace=0.0) # set the spacing between axes.\n",
    "ax = fig.add_subplot(gs[0, :])\n",
    "\n",
    "for sensor in requested_sensor :\n",
    "    \n",
    "    ls_values = [] # listes des valeurs\n",
    "    ls_time   = [] # listes des temps \n",
    "    ls_var    = [] # listes des écarts-types\n",
    "    \n",
    "    print(sensor)\n",
    "    for IR in dict_value_IR :\n",
    "        ls_values.append(pseudo_temp[sensor][IR][\"values\"])\n",
    "        ls_time.append(pseudo_temp[sensor][IR][\"time\"])\n",
    "        ls_var.append(pseudo_temp[sensor][IR][\"var\"])\n",
    "        \n",
    "    # [ val - sigma , val + sigma]\n",
    "    ls_sigma = [np.array(ls_values)-np.array(ls_var),np.array(ls_values)+np.array(ls_var)]\n",
    "    SLICE = dict_temp_sensor[sensor]\n",
    "    \n",
    "     \n",
    "    # Plot de la température des sondes \n",
    "    plottingtemp_single_label_IR_a(SLICE,fig,ax,'T4',200,6)\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax3 = ax.twinx() # instantiate a second axes that shares the same x-axis\n",
    "    color = \"tab:red\"\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax.grid()\n",
    "\n",
    "    # Plot de la pseudo Température \n",
    "    ax3.plot(ls_time,ls_values,color = color)\n",
    "    ax3.plot(ls_time,ls_values,'ro',color = color)\n",
    "    ax3.tick_params(axis = 'y', labelcolor = color)\n",
    "    ax3.set_ylabel(\"Pseudo Température\", color = color, fontsize = 20)\n",
    "    ax3.set_ylim(-5,30)\n",
    "    \n",
    "    \n",
    "    for w in range(len(ls_time)) :\n",
    "        ax3.text(ls_time[w],ls_values[w]+0.5,str(ls_var[w])[0:5],fontsize = 15) # valeurs d'écart type\n",
    "        \n",
    "       \n",
    "    \n",
    "    # Interval de confiance +/- sigma \n",
    "    ax3.plot(ls_time,ls_sigma[0],'m',label = '- sigma') # value - sigma\n",
    "    ax3.plot(ls_time,ls_sigma[1],'m',label = '+ sigma') # value + sigma\n",
    "    ax3.legend(loc='upper right', bbox_to_anchor=(1, 0.9))\n",
    "    \n",
    "        # plot des patchs IRs\n",
    "    for k,IR in enumerate(dict_IR) :\n",
    "        ax2 = fig.add_subplot(gs[1, k])\n",
    "        \n",
    "        window_IR = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"all_band\"]\n",
    "        window_transform_IR = dict_IR[IR][\"dict_windows_param\"][requested_sensor[0]][\"win_transform\"]\n",
    "        extent = plotting_extent(window_IR,window_transform_IR)\n",
    "        \n",
    "        sub_fig = ax2.imshow(window_IR,extent = extent,cmap ='viridis')\n",
    "        ax2.set_title(IR,fontsize = 20,pad = 20)\n",
    "        fig.colorbar(sub_fig,ax=ax2,fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Plot des targets\n",
    "        TARGET = sensor_coord.loc[sensor_coord[\"SensorName\"]==sensor]\n",
    "        X = np.array(TARGET[\"x\"],dtype = float)\n",
    "        Y = np.array(TARGET[\"y\"],dtype=float)\n",
    "        ax2.plot(X,Y,'r*')\n",
    "        \n",
    "        # Plot des points choisi pour la pseudo-temp\n",
    "        for k in range( len(dict_value_IR[IR][sensor][\"value\"])) :\n",
    "            ax2.plot(dict_value_IR[IR][sensor][\"x\"][k],dict_value_IR[IR][sensor][\"y\"][k],'ro')\n",
    "    \n",
    "    # Ajout d'un polynome de degrée 6\n",
    "    colors = ['forestgreen', 'green', 'lime']\n",
    "    lw = 2\n",
    "    X = np.array(SLICE[\"Time\"]).reshape(-1,1)\n",
    "    y = np.array(SLICE[\"T4\"]).reshape(-1,1)\n",
    "    for count, degree in enumerate([5]):\n",
    "        model = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "        model.fit(X, y)\n",
    "        y_plot = model.predict(X)\n",
    "        ax.plot(X, y_plot, color=colors[count], linewidth=lw,\n",
    "                 label=\"degree %d\" % degree)\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "        \n",
    "plt.title(sensor,fontsize = 20)\n",
    "ax.set_xticklabels([str(time.hour)+':'+str(time.minute) for time in SLICE['Time']][::8])\n",
    "ax.set_xlabel('Time' + ' 2019-04-19' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout de la RMSE/RMS entre la Pseudo-Temp° et la T° du sensor, pas avec la Pseudo-Temp° interpolée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "requested_sensor = [\"S1\",\"S2\",\"S3-AIR\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"S10\"]\n",
    "\n",
    "\n",
    "for sensor in requested_sensor :\n",
    "    \n",
    "    # Propriétés graphiques\n",
    "    fig = plt.figure(figsize=(25,15))\n",
    "\n",
    "\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 12\n",
    "    BIGGER_SIZE = 15\n",
    "\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "    gs = GridSpec(2, 10, figure=fig)\n",
    "    gs.update(wspace = 0.5, hspace=0.0) # set the spacing between axes.\n",
    "    ax = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    ls_values = [] # listes des valeurs\n",
    "    ls_time   = [] # listes des temps \n",
    "    ls_var    = [] # listes des écarts-types\n",
    "    rms       = [] # listes des RMS\n",
    "    \n",
    "    print(sensor)\n",
    "    for IR in dict_value_IR :\n",
    "        ls_values.append(pseudo_temp[sensor][IR][\"values\"])\n",
    "        ls_time.append(pseudo_temp[sensor][IR][\"time\"])\n",
    "        ls_var.append(pseudo_temp[sensor][IR][\"var\"])\n",
    "        \n",
    "    # [ val - sigma , val + sigma]\n",
    "    ls_sigma = [np.array(ls_values)-np.array(ls_var),np.array(ls_values)+np.array(ls_var)]\n",
    "    SLICE = dict_temp_sensor[sensor]\n",
    "    \n",
    "     \n",
    "    # Plot de la température des sondes \n",
    "    plottingtemp_single_label_IR_a(SLICE,fig,ax,'T4',200,6)\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax3 = ax.twinx() # instantiate a second axes that shares the same x-axis\n",
    "    color = \"tab:red\"\n",
    "    ax.set_ylim(-5,30)\n",
    "    ax.grid()\n",
    "\n",
    "    # Plot de la pseudo Température \n",
    "    ax3.plot(ls_time,ls_values,color = color)\n",
    "    ax3.plot(ls_time,ls_values,'ro',color = color)\n",
    "    ax3.tick_params(axis = 'y', labelcolor = color)\n",
    "    ax3.set_ylabel(\"Pseudo Température\", color = color, fontsize = 20)\n",
    "    ax3.set_ylim(-5,30)\n",
    "    \n",
    "    #Affichage des valeurs de RMS\n",
    "    for w in range(len(ls_time)) :\n",
    "        y_actual    = SLICE.loc[SLICE[\"Time\"]==ls_time[w]][\"T4\"] \n",
    "        y_predicted = ls_values[w]\n",
    "        rms.append(np.absolute(np.mean(y_actual-y_predicted)))\n",
    "        ax3.text(ls_time[w],ls_values[w]+0.5,str(rms[w])[0:5],fontsize = 15) # valeurs RMS\n",
    "\n",
    "        \n",
    "    # Affichage de la valeur de RMSE (une valeur)\n",
    "    ls_slice_value = []\n",
    "    for time in ls_time : # compare uniquement les pseudo-temp et les valeurs de sonde \n",
    "        ls_slice_value.append(float(SLICE[\"T4\"].loc[SLICE['Time'] == time]))\n",
    "    \n",
    "    RMSE = mean_squared_error(ls_slice_value,ls_values,squared=False)\n",
    "    ax3.text(SLICE[\"Time\"].iloc[-8],28,'RMSE = ' + str(RMSE)[0:5],fontsize = 15) # valeurs RMSE\n",
    "    \n",
    "       \n",
    "    \n",
    "    # Interval de confiance +/- sigma \n",
    "    #ax3.plot(ls_time,ls_sigma[0],'m',label = '- sigma') # value - sigma\n",
    "    #ax3.plot(ls_time,ls_sigma[1],'m',label = '+ sigma') # value + sigma\n",
    "    #ax3.legend(loc='upper right', bbox_to_anchor=(1, 0.9))\n",
    "    \n",
    "    # plot des patchs IRs\n",
    "    for k,IR in enumerate(dict_IR) :\n",
    "        ax2 = fig.add_subplot(gs[1, k])\n",
    "        \n",
    "        window_IR = dict_IR[IR][\"dict_windows_param\"][sensor][\"all_band\"]\n",
    "        window_transform_IR = dict_IR[IR][\"dict_windows_param\"][sensor][\"win_transform\"]\n",
    "        extent = plotting_extent(window_IR,window_transform_IR)\n",
    "        \n",
    "        sub_fig = ax2.imshow(window_IR,extent = extent,cmap ='viridis')\n",
    "        ax2.set_title(IR,fontsize = 20,pad = 20)\n",
    "        fig.colorbar(sub_fig,ax=ax2,fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Plot des targets\n",
    "        TARGET = sensor_coord.loc[sensor_coord[\"SensorName\"]==sensor]\n",
    "        X = np.array(TARGET[\"x\"],dtype = float)\n",
    "        Y = np.array(TARGET[\"y\"],dtype=float)\n",
    "        ax2.plot(X,Y,'r*')\n",
    "        \n",
    "        # Plot des points choisi pour la pseudo-temp\n",
    "        for k in range( len(dict_value_IR[IR][sensor][\"value\"])) :\n",
    "            ax2.plot(dict_value_IR[IR][sensor][\"x\"][k],dict_value_IR[IR][sensor][\"y\"][k],'ro')\n",
    "    \n",
    "    # Ajout d'un polynome de degrée n\n",
    "    colors = ['forestgreen', 'green', 'lime']\n",
    "    lw = 2\n",
    "    #X = np.array(SLICE[\"Time\"]).reshape(-1,1)\n",
    "    #y = np.array(SLICE[\"T4\"]).reshape(-1,1)\n",
    "    X = np.array(ls_time,dtype='datetime64[ns]').reshape(-1,1)\n",
    "    y = np.array(ls_values).reshape(-1,1)\n",
    "    for count, degree in enumerate([5]):\n",
    "        model = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "        model.fit(X, y)\n",
    "        y_plot = model.predict(X)\n",
    "        ax.plot(X, y_plot, color=colors[count], linewidth=lw,\n",
    "                 label=\"degree %d\" % degree)\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "        \n",
    "    ax.set_title(sensor +\" et valeurs de RMS pour chaque pseudo température\",fontsize = 20)\n",
    "    ax.set_xticklabels([str(time.hour)+':'+str(time.minute) for time in SLICE['Time']][::8])\n",
    "    ax.set_xlabel('Time (heures:minutes)' + ' 2019-04-19' )\n",
    "    fileout =  \"C:/Users/Alexandre/Desktop/Cours/Stage/Temp_vs_IR/2m/\"+ str(sensor)+\".png\"\n",
    "    #fig.savefig(fileout)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_slice_value = []\n",
    "for time in ls_time :\n",
    "    print(time)\n",
    "    ls_slice_value.append(float(SLICE[\"T4\"].loc[SLICE['Time'] == time]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(ls_slice_value,ls_values,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual    = SLICE.loc[SLICE[\"Time\"]==ls_time[w]][\"T4\"] \n",
    "y_predicted = ls_values[w]\n",
    "        rms.append(mean_squared_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "colors = ['teal', 'yellowgreen', 'gold']\n",
    "lw = 2\n",
    "X = np.array(SLICE[\"Time\"]).reshape(-1,1)\n",
    "y = np.array(SLICE[\"T4\"]).reshape(-1,1)\n",
    "for count, degree in enumerate([3, 4, 5]):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "    model.fit(X, y)\n",
    "    y_plot = model.predict(X)\n",
    "    plt.plot(X, y_plot, color=colors[count], linewidth=lw,\n",
    "             label=\"degree %d\" % degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop = dict_IR['IR_6H55'][\"dict_windows\"][\"S10\"]\n",
    "mid_x = hop.iloc[len(hop)//2][\"x\"]\n",
    "mid_y = hop.iloc[76//2 -1][\"y\"]\n",
    "theta = [0,np.pi/2,np.pi,np.pi*3/4]\n",
    "r = 1\n",
    "ls_x = [] ; ls_y = []\n",
    "print(\"mid_x :\",mid_x,\"mid_y :\",mid_y)\n",
    "for THETA in theta :\n",
    "    x = mid_x + r*np.cos(THETA)\n",
    "    y = mid_y + r*np.sin(THETA)\n",
    "    print(\"x :\",x,\"y :\",y)\n",
    "    ls_x.append(x) ; ls_y.append(y)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methode pour discriminer des IRs\n",
    "\n",
    "request_IR = ['IR_11H27',\"IR_12H31\"]\n",
    "request_sensor = [\"S9\",\"S2\",\"S4\"]\n",
    "requested_IR = Piren_IR[request_IR]\n",
    "\n",
    "## Creation de mask pour plusieurs images IR\n",
    "requested_ls_mask_image, requested_ls_out_transform= IR_mask(requested_IR.loc[\"IR_src\"],requested_shapes,requested_ls_coord_circle)\n",
    "#Methode pour discriminer des sondes\n",
    "\n",
    "## creation d'un rayon de taille r autour des sensors\n",
    "ls_sensor = Sensor_coord[\"SensorName\"] # : toutes les sondes\n",
    "ls_coord_circle,Shape_to_json,circle_name = circle_sensor(ls_sensor,Sensor_coord)\n",
    "\n",
    "#Creat a shape in GeoJSON format in order to be read with rio and \n",
    "#serve as mask to crop selected area in the shape\n",
    "\n",
    "shapes,shapes_names = circle_to_shape(ls_coord_circle,Shape_to_json,circle_name)\n",
    "\n",
    "requested_names  =  []\n",
    "requested_shapes =  []\n",
    "requested_ls_coord_circle = []\n",
    "for i,names in enumerate(shapes_names) :\n",
    "    for k in range(len(request_sensor)) :  \n",
    "        if names == request_sensor[k] :\n",
    "            requested_names.append(names)\n",
    "            requested_shapes.append(shapes[i])\n",
    "            requested_ls_coord_circle.append(ls_coord_circle[i])\n",
    "            \n",
    "requested_names\n",
    "requested_shapes\n",
    "len(requested_ls_coord_circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1e moitié des sondes IR, avec une echelle defini par l'utilisateur\n",
    "lim_min = -10\n",
    "lim_max = 20\n",
    "lim_tif = len(Piren_IR.loc[\"IR_src\"])\n",
    "lim_tif = 4\n",
    "fig_IR,axtemp=plt.subplots(lim_tif,len(ls_sensor),figsize=(25,25))\n",
    "for i in range(lim_tif) :\n",
    "    for k,mask_image in enumerate(ls_mask_image[i]) :\n",
    "        sub_fig = axtemp[i,k].imshow(mask_image[0],cmap ='viridis')#,vmin = lim_min,vmax = lim_max)\n",
    "        sub =show(mask_image, transform= ls_out_transform[i],\n",
    "            ax=axtemp[i,k],title=[ls_sensor[k]+'  '+filetif[i]])#,vmin = lim_min,vmax = lim_max)\n",
    "\n",
    "        sub_fig_colorbar=fig_IR.colorbar(sub_fig,ax = axtemp[i,k])\n",
    "        sub_fig_colorbar.set_label('T(°C)', rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chercher si une variable existe ou pas\n",
    "B = 5\n",
    "try: \n",
    "    B\n",
    "except NameError:\n",
    "        A = 'AHA'\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discrimination des IRs\n",
    "Piren_IR[request].loc[\"IR_src\"]\n",
    "len(ls_mask_image_requested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(Piren_IR.loc[\"IR_src\"])):\n",
    "    print(Piren_IR.loc[\"IR_src\"][i])\n",
    "print(\"nombre d'image IR :\",len(Piren_IR.loc[\"IR_src\"]))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1e moitié des sondes IR, avec une echelle defini par l'utilisateur\n",
    "lim_min = -10\n",
    "lim_max = 20\n",
    "len_IR = len(requested_IR)\n",
    "len_sondes =\n",
    "fig_IR,axtemp=plt.subplots(lim_tif,len(ls_sensor),figsize=(25,25))\n",
    "for i in range(lim_tif) :\n",
    "    for k,mask_image in enumerate(ls_mask_image[i]) :\n",
    "        sub_fig = axtemp[i,k].imshow(mask_image[0],cmap ='viridis')#,vmin = lim_min,vmax = lim_max)\n",
    "        sub =show(mask_image, transform= ls_out_transform[i],\n",
    "            ax=axtemp[i,k],title=[ls_sensor[k]+'  '+filetif[i]])#,vmin = lim_min,vmax = lim_max)\n",
    "\n",
    "        sub_fig_colorbar=fig_IR.colorbar(sub_fig,ax = axtemp[i,k])\n",
    "        sub_fig_colorbar.set_label('T(°C)', rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot de tous les histogram autours des sondes \n",
    "\n",
    "fig2,(axhist)=plt.subplots(9,figsize=(10,30),sharex=True, sharey=True)\n",
    "for k,mask_image in enumerate(ls_mask_image) :\n",
    "    show_hist(mask_image, bins=50, histtype='stepfilled', lw=0.0, stacked=False, ax=axhist[k], alpha=0.3, title=circle_name[k][k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot de chaque couple histo/image\n",
    "\n",
    "for k,mask_image in enumerate(ls_mask_image) :\n",
    "    fig2,(axhist,axrgb)=plt.subplots(1,2,figsize=(50,50))\n",
    "    show_hist(mask_image, bins=50, histtype='stepfilled', lw=0.0, stacked=False, ax=axhist, alpha=0.3, title=circle_name[k][k])\n",
    "    show(mask_image, transform=ls_out_transform,ax=axrgb,title=circle_name[k][k])\n",
    "    #plt.plot(np.array(Sensor_coord[\"x\"][k]),np.array(Sensor_coord[\"y\"][k]),'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,len(Piren_IR_ls)) :\n",
    "    Piren_IR.assign(locals()[IR_%s % Piren_IR_name[1][k]] = Piren_IR_ls[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,len(filetif)) :\n",
    "    locals()['SS_%s' % filetif[k]] = 1\n",
    "    print(locals()['SS_%s' % filetif[k]])\n",
    "\n",
    "locals()['SS_%s' % filetif[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_meta = IR_src.meta\n",
    "for k in range(len(list_coord_circle)) :\n",
    "    out_image, out_transform = rio.mask.mask(IR_src, shapes[k], crop=True, filled=False)\n",
    "    \"\"\"\n",
    "    And update height and width of cropped image with its meta data\"\"\"\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "             \"height\": out_image.shape[1],\n",
    "             \"width\": out_image.shape[2],\n",
    "             \"transform\": out_transform})\n",
    "    \n",
    "    fig2,(axhist, axrgb)=plt.subplots(1,2, figsize=(21,7))\n",
    "    show(out_image, transform=out_transform,ax=axrgb)\n",
    "    #plt.plot(np.array(Sensor_coord[\"x\"][k]),np.array(Sensor_coord[\"y\"][k]),'bo')\n",
    "    show_hist(out_image, bins=50, histtype='stepfilled', lw=0.0, stacked=False, ax=axhist, alpha=0.3, title=circle_name[k][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_meta = IR_src.meta\n",
    "out_image, out_transform = rio.mask.mask(IR_src, shapes[0], crop=True, filled=False)\n",
    "\"\"\"\n",
    "And update height and width of cropped image with its meta data\"\"\"\n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "         \"height\": out_image.shape[1],\n",
    "         \"width\": out_image.shape[2],\n",
    "         \"transform\": out_transform})\n",
    "\n",
    "show(out_image, transform=out_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rasterio \n",
    "IR_src = rio.open(os.path.join(ls_path_tif[0]))\n",
    "#show((src,1)) # Affiche la premiere bande\n",
    "#fig1,ax1 = show((src,1),cmap='viridis')\n",
    "Piren_IR_array=IR_src.read(1) # Lit la bande 1\n",
    "Piren_Limits = plotting_extent(IR_src) # Limites\n",
    "Piren_Limits\n",
    "Piren_res = IR_src.res # resolution\n",
    "Piren_res\n",
    "fig_IR,ax_IR=plt.subplots(1,figsize=(50,50))\n",
    "sub_fig=ax_IR.imshow(Piren_IR_array,extent=Piren_Limits,cmap='viridis')\n",
    "ax_IR.set_xlabel('x')\n",
    "ax_IR.set_ylabel('y')\n",
    "ax_IR.set_label(ls_path_tif[0])\n",
    "sub_fig_colorbar=fig_IR.colorbar(sub_fig)\n",
    "sub_fig_colorbar.set_label('T(°C)', rotation=0, labelpad=-28, y=1.05)\n",
    "\n",
    "## Plot des coordonnees de la sonde\n",
    "#plt.plot(np.array(Sensor_coord[\"x\"]),np.array(Sensor_coord[\"y\"]),'bo')\n",
    "## Plot des coordonnees de la sonde\n",
    "#ax_IR.annotate(str(sensor_GPS[\"SensorName\"]),[np.array(Sensor_coord[\"x\"]),np.array(Sensor_coord[\"y\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Piren_IR_test = pd.DataFrame(np.array([Piren_IR[0][0],Piren_IR[0][1],Piren_IR[0][2]],dtype=object).T,index =\n",
    "                            [\"IR_array\",\"Limits\",\"IR_src\"],columns = ['001'])\n",
    "Piren_IR_test['001']['IR_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = np.array([Piren_IR_array,Piren_Limits,IR_src],dtype=object).T\n",
    "sss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat a shape in GeoJSON format in order to be read with rio and \n",
    "#serve as mask to crop selected area in the shape\n",
    "shapes = []\n",
    "for j in range(len(list_coord_circle)):\n",
    "    with fiona.open(Shape_to_json[j],'r') as Test_image:\n",
    "        #print(list(Test_image)) # On va chercher à chopper la propriete Geometry\n",
    "        shapes.append([feature[\"geometry\"] for feature in Test_image])\n",
    "print(len(shapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_coord = len(Sensor_coord)\n",
    "value = []\n",
    "for k in range(0,len_coord) :\n",
    "    for val in IR_src.sample([(float(Sensor_coord[\"x\"][k]),float(Sensor_coord[\"y\"][k]))]): \n",
    "        value.append(val)\n",
    "    coord_value = np.array([Sensor_coord[\"x\"],Sensor_coord[\"y\"],value])\n",
    "coord_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Piren_IR_array.shape\n",
    "IR_src.tags\n",
    "aaa = rio.sample.sample_gen(IR_src,([523628.71,5366296.81]),indexes=None,masked=False)\n",
    "for val in IR_src.sample([(float(Sensor_coord[\"x\"][0]),float(Sensor_coord[\"y\"][0]))]): \n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recupere les noms des IR dans le dossier path, \n",
    "#par defaut = './traitement_PIREN/'\n",
    "ls_path_tif = path_IR()\n",
    "ls_path_tif[0][0]\n",
    "for test_tif in ls_path_tif:\n",
    "    print(test_tif[0],type(test_tif[0]))\n",
    "    if test_tif[0].find('003') > 0:\n",
    "        aaa = test_tif[0]\n",
    "        break\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouverture et recupération des positions de Sensors \n",
    "Sensor_Name_File_GPS=[]\n",
    "Sensor_x=[]\n",
    "Sensor_y=[]\n",
    "k = 0\n",
    "with open(\"./traitement_PIREN/sondes_gps_UTM31N_phase1.txt\") as File_GPS:\n",
    "    csvReader=csv.reader(File_GPS, delimiter='\\t')\n",
    "    for row in csvReader:\n",
    "        Sensor_Name_File_GPS.append(row[0]) ## colonne nom du fichier\n",
    "        # str list to float list, for plot option\n",
    "        Sensor_x.append(float(row[1])) # colonne coordonnees x \n",
    "        Sensor_y.append(float(row[2])) # colonne coordonnees y\n",
    "        print(\"x =\",Sensor_x[k],'  y =',Sensor_y[k])\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Recupere les noms des Sensors dans le dossier path, par defaut = './Data/'\n",
    "path = './traitement_PIREN/'\n",
    "ls_path_tif = []\n",
    "ls_path = os.listdir(path=path)\n",
    "for tif in ls_path:\n",
    "    if tif.find('.tif') > 0 :\n",
    "        ls_path_tif.append([path+tif])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensor_coord =pd.DataFrame(np.array([Sensor_Name_File_GPS,Sensor_x,Sensor_y]).T)\n",
    "Sensor_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creation d'un rayon de taille r autour d une Sensor (S10)\n",
    "list_coord_circle = []\n",
    "Shape_to_json=[]\n",
    "circle_name = []\n",
    "\n",
    "len_sensor = len(Sensor_coord['SensorName'])\n",
    "for SensorName in Sensor_coord['SensorName'] :\n",
    "    sensor_GPS = Sensor_coord.loc[Sensor_coord['SensorName']==str(SensorName)]\n",
    "    center = Point(sensor_GPS[\"x\"],sensor_GPS[\"y\"])\n",
    "    circle = center.buffer(1)\n",
    "    #Val de chaque extremitees du cercle\n",
    "    x_circle,y_circle = circle.exterior.xy\n",
    "    list_coord_circle.append([np.array(x_circle),np.array(y_circle)])\n",
    "    # Transfo des donnees en Geoseries : \n",
    "    #Json -> https://fr.wikipedia.org/wiki/JavaScript_Object_Notation\n",
    "    # Format qui contient toutes les proprietes + points ext du cercle\n",
    "    Shape_to_json.append(gpd.GeoSeries([circle]).to_json())\n",
    "    circle_name.append(sensor_GPS['SensorName'])\n",
    "    list_coord_circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test = gpd.GeoSeries([circle])\n",
    "plot_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ultérieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creation d'un rayon de taille r autour des sensors\n",
    "ls_sensor = Sensor_coord[\"SensorName\"] # : toutes les sondes\n",
    "ls_coord_circle,Shape_to_json,circle_name = circle_sensor(ls_sensor,Sensor_coord)\n",
    "\n",
    "#Creat a shape in GeoJSON format in order to be read with rio and \n",
    "#serve as mask to crop selected area in the shape\n",
    "\n",
    "shapes,shapes_names = circle_to_shape(ls_coord_circle,Shape_to_json,circle_name)\n",
    "\n",
    "## Creation de mask pour plusieurs images IR\n",
    "ls_mask_image, ls_out_transform= IR_mask(Piren_IR.loc[\"IR_src\"],shapes,ls_coord_circle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot toutes les sondes pour ttes IR, avec une echelle defini par l'utilisateur\n",
    "lim_min = -20\n",
    "lim_max = 40\n",
    "fig_IR,axtemp=plt.subplots(10,10,figsize=(40,40),sharex=True, sharey=True)\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 15\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "for i in range(len(Piren_IR.loc[\"IR_src\"])) :\n",
    "    for k,mask_image in enumerate(ls_mask_image[i]) :\n",
    "        sub_fig = axtemp[i,k].imshow(mask_image[0],cmap ='viridis',vmin = lim_min,vmax = lim_max)\n",
    "        sub =show(mask_image, transform= ls_out_transform[i],vmin = lim_min,vmax = lim_max,\n",
    "            ax=axtemp[i,k],title=[circle_name[k][k]+'  '+filetif[i]])\n",
    "\n",
    "sub_fig_colorbar=fig_IR.colorbar(sub_fig,ax = axtemp[0:10])\n",
    "sub_fig_colorbar.set_label('T(°C)', rotation=0, labelpad=-28, y=1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for IR in Piren_IR :\n",
    "        print(IR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## echantillon de sonde / IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Methode pour discriminer des IRs\n",
    "\n",
    "request_IR = ['IR_11H27']\n",
    "request_sensor = [\"S9\"]\n",
    "requested_IR = Piren_IR[request_IR]\n",
    "\n",
    "\n",
    "## creation d'un rayon de taille r autour des sensors\n",
    "ls_sensor = Sensor_coord[\"SensorName\"] # : toutes les sondes\n",
    "ls_coord_circle,Shape_to_json,circle_name = circle_sensor(ls_sensor,Sensor_coord)\n",
    "\n",
    "#Creat a shape in GeoJSON format in order to be read with rio and \n",
    "#serve as mask to crop selected area in the shape\n",
    "\n",
    "shapes,shapes_names = circle_to_shape(ls_coord_circle,Shape_to_json,circle_name)\n",
    "\n",
    "requested_names  =  []\n",
    "requested_shapes =  []\n",
    "requested_ls_coord_circle = []\n",
    "for i,names in enumerate(shapes_names) :\n",
    "    for k in range(len(request_sensor)) :  \n",
    "        if names == request_sensor[k] :\n",
    "            requested_names.append(names)\n",
    "            requested_shapes.append(shapes[i])\n",
    "            requested_ls_coord_circle.append(ls_coord_circle[i])\n",
    "            \n",
    "## Creation de mask pour plusieurs images IR\n",
    "requested_ls_mask_image, requested_ls_out_transform= IR_mask(requested_IR.loc[\"IR_src\"],requested_shapes,requested_ls_coord_circle)\n",
    "#Methode pour discriminer des sondes\n",
    "\n",
    "## Plot d'un echantillon i = IR , k = Sondes\n",
    "lim_min = -10\n",
    "lim_max = 20\n",
    "len_IR = len(requested_ls_mask_image)\n",
    "len_shapes = len(requested_shapes)\n",
    "step = 1\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 15\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title !!! \n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "if len_IR == 1 and len_shapes == 1 : \n",
    "    \n",
    "    fig_IR,axtemp=plt.subplots(1,figsize=(25,25))\n",
    "    \n",
    "    for i in range(len_IR) :\n",
    "        for k,mask_image in enumerate(requested_ls_mask_image[i]) :\n",
    "            sub_fig = axtemp.imshow(mask_image[0],cmap ='viridis')#,vmin = lim_min,vmax = lim_max)\n",
    "            sub =show(mask_image, transform= requested_ls_out_transform[i],\n",
    "                ax=axtemp,title=[requested_names[k]+'  '+request_IR[i]])#,vmin = lim_min,vmax = lim_max)\n",
    "\n",
    "            sub_fig_colorbar=fig_IR.colorbar(sub_fig,ax = axtemp)\n",
    "            sub_fig_colorbar.set_label('T(°C)', rotation=0)\n",
    "else :\n",
    "        \n",
    "        fig_IR,axtemp=plt.subplots(len_IR,len_shapes,figsize=(25,25))\n",
    "\n",
    "        for i in range(len_IR) :\n",
    "            for k,mask_image in enumerate(requested_ls_mask_image[i]) :\n",
    "                sub_fig = axtemp[i,k].imshow(mask_image[0],cmap ='viridis')#,vmin = lim_min,vmax = lim_max)\n",
    "                sub =show(mask_image, transform= requested_ls_out_transform[i],\n",
    "                    ax=axtemp[i,k],title=[requested_names[k]+'  '+request_IR[i]])#,vmin = lim_min,vmax = lim_max)\n",
    "\n",
    "                sub_fig_colorbar=fig_IR.colorbar(sub_fig,ax = axtemp[i,k])\n",
    "                sub_fig_colorbar.set_label('T(°C)', rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison avec les données de la sondes la plus shallow (5cm) a +/-1 h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A MODIFIER \n",
    "date_1='2019-04-14 12:30:00'\n",
    "date_2='2019-04-14 14:30:00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Crée des Tableaux pour chaque sonde selon leur nom : RawS1,RawS2,..\n",
    "### Et un dictionnaire associee\n",
    "\n",
    "ls_path = path_sonde()\n",
    "dict_temp_sensor = {}\n",
    "dict_slice_temp = {}\n",
    "\n",
    "for i,ls_path_sonde in enumerate(ls_path):\n",
    "    name = ls_path_sonde[0][ls_path_sonde[0].find(\"S\"):(ls_path_sonde[0].find(\".csv\"))]\n",
    "    Raw = readingtemp(ls_path_sonde[0])\n",
    "    dict_temp_sensor[name] = Raw\n",
    "    dict_slice_temp[name] = slice_raw(dict_temp_sensor[name],date_1,date_2)\n",
    "    print(\"completed :\",name)\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_temp_sensor[\"S9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methode pour discriminer des IRs\n",
    "\n",
    "request_IR = ['IR_6H55']\n",
    "request_sensor = [\"S10\"]\n",
    "SLICE = sliceS10  ## à remplacer \n",
    "\n",
    "requested_IR = Piren_IR[request_IR]\n",
    "## creation d'un rayon de taille r autour des sensors\n",
    "ls_sensor = Sensor_coord[\"SensorName\"] # : toutes les sondes\n",
    "ls_coord_circle,Shape_to_json,circle_name = circle_sensor(ls_sensor,Sensor_coord)\n",
    "\n",
    "#Creat a shape in GeoJSON format in order to be read with rio and \n",
    "#serve as mask to crop selected area in the shape\n",
    "shapes,shapes_names = circle_to_shape(ls_coord_circle,Shape_to_json,circle_name)\n",
    "\n",
    "\n",
    "requested_names  =  []\n",
    "requested_shapes =  []\n",
    "requested_ls_coord_circle = []\n",
    "for i,names in enumerate(shapes_names) :\n",
    "    for k in range(len(request_sensor)) :  \n",
    "        if names == request_sensor[k] :\n",
    "            requested_names.append(names)\n",
    "            requested_shapes.append(shapes[i])\n",
    "            requested_ls_coord_circle.append(ls_coord_circle[i])\n",
    "            \n",
    "## Creation de mask pour plusieurs images IR\n",
    "requested_ls_mask_image, requested_ls_out_transform= IR_mask(requested_IR.loc[\"IR_src\"],requested_shapes,requested_ls_coord_circle)\n",
    "#Methode pour discriminer des sondes\n",
    "\n",
    "## Plot d'un echantillon i = IR , k = Sondes\n",
    "lim_min = -10\n",
    "lim_max = 20\n",
    "len_IR = len(requested_ls_mask_image)\n",
    "len_shapes = len(requested_shapes)\n",
    "step = 1\n",
    "\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 28 }\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "\n",
    "\n",
    "fig_IR,axtemp=plt.subplots(2,1,figsize=(25,25))\n",
    "\n",
    "for i in range(len_IR) :\n",
    "    for k,mask_image in enumerate(requested_ls_mask_image[i]) :\n",
    "        sub_fig = axtemp[0].imshow(mask_image[0],cmap ='viridis')#,vmin = lim_min,vmax = lim_max)\n",
    "        sub =show(mask_image, transform= requested_ls_out_transform[i],\n",
    "            ax=axtemp[0],title=[requested_names[k]+'  '+request_IR[i]])#,vmin = lim_min,vmax = lim_max)\n",
    "\n",
    "        sub_fig_colorbar=fig_IR.colorbar(sub_fig,ax = axtemp[0])\n",
    "        sub_fig_colorbar.set_label('T(°C)', rotation=0)\n",
    "\n",
    "plottingtemp_single_label_IR(SLICE,fig_IR,axtemp[1],'T4',step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif = \"./traitement_PIREN/vis_piren_phase_1_cropped_clustered_7k.tif\"\n",
    "dataset = rio.open(tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
